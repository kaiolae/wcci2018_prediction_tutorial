{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Character Level RNN using LSTM cells.\n",
    "\n",
    "- Trains on Star Trek episode titles\n",
    "- Outputs \"fake\" titles.\n",
    "\n",
    "Much comes from a [Keras example](https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py).\n",
    "\n",
    "## Setup Environment\n",
    "\n",
    "- Import Keras\n",
    "- Open up the Star Trek corpus\n",
    "- We need to translate the textual data into a format that the RNN can accept as input.\n",
    "- Give each letter an index and create dictionaries to translate from index to character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 11010\n",
      "total chars: 49\n",
      "Max: 50\n",
      "Mean: 14.001362397820163\n",
      "Median: 13.0\n",
      "Min: 2\n",
      "Character Dictionary:  {'2': 11, '!': 2, 'x': 43, ')': 5, '.': 8, 'à': 46, '7': 15, 'h': 27, 'f': 25, 'z': 45, 'n': 33, '0': 9, ',': 6, 'r': 37, 'i': 28, 'k': 30, 'e': 24, '?': 19, 'c': 22, '1': 10, 'j': 29, '8': 16, '5': 14, 't': 39, 'u': 40, '9': 17, 'p': 35, 'm': 32, 'd': 23, 'g': 26, '4': 13, 'y': 44, ' ': 1, 'l': 31, 'w': 42, 'q': 36, ':': 18, '-': 7, 'b': 21, 's': 38, 'é': 47, '’': 48, '\\n': 0, 'o': 34, \"'\": 3, '3': 12, '(': 4, 'v': 41, 'a': 20}\n",
      "Inverse Character Dictionary:  {0: '\\n', 1: ' ', 2: '!', 3: \"'\", 4: '(', 5: ')', 6: ',', 7: '-', 8: '.', 9: '0', 10: '1', 11: '2', 12: '3', 13: '4', 14: '5', 15: '7', 16: '8', 17: '9', 18: ':', 19: '?', 20: 'a', 21: 'b', 22: 'c', 23: 'd', 24: 'e', 25: 'f', 26: 'g', 27: 'h', 28: 'i', 29: 'j', 30: 'k', 31: 'l', 32: 'm', 33: 'n', 34: 'o', 35: 'p', 36: 'q', 37: 'r', 38: 's', 39: 't', 40: 'u', 41: 'v', 42: 'w', 43: 'x', 44: 'y', 45: 'z', 46: 'à', 47: 'é', 48: '’'}\n"
     ]
    }
   ],
   "source": [
    "## Much borrowed from https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.callbacks import LambdaCallback\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "text = open(\"startrekepisodes.txt\").read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocabulary_size = len(chars)\n",
    "print('total chars:', vocabulary_size)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "\n",
    "# How long is a title?\n",
    "titles = text.split('\\n')\n",
    "lengths = np.array([len(n) for n in titles])\n",
    "print(\"Max:\", np.max(lengths))\n",
    "print(\"Mean:\", np.mean(lengths))\n",
    "print(\"Median:\", np.median(lengths))\n",
    "print(\"Min:\", np.min(lengths))\n",
    "\n",
    "# hence choose 30 as seuence length to train on.\n",
    "print(\"Character Dictionary: \", char_indices)\n",
    "print(\"Inverse Character Dictionary: \", indices_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup Training Data\n",
    "\n",
    "- Cut up the corpus into semi-redundant sequences of 30 characters.\n",
    "- Change indices into \"one-hot\" vector encodings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"figures/slicing_text.png\",width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 3660\n",
      "the man trap\n",
      "charlie x\n",
      "where n\n",
      "o\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 30\n",
    "step = 3\n",
    "\n",
    "sentences = [] #The training data\n",
    "next_chars = [] #The training labels\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    \n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print(sentences[0])\n",
    "print(next_chars[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Onehot encoding:\n",
    "* a -> [1, 0, 0, ..., 0]\n",
    "* b -> [0, 1, 0, ..., 0]\n",
    "* ...\n",
    "\n",
    "Each training sample becomes 2D tensor:\n",
    "* \"This is the text\" -> X = [[0, 0, ..., 1, 0, ..., 0], ..., [0, 0, ..., 1, 0, ... 0]]\n",
    "\n",
    "Each target (next letter) becomes 1D onehot tensor:\n",
    "* a -> y = [1, 0, 0, ..., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done preparing training corpus, shapes of sets are:\n",
      "X shape: (3660, 30, 49)\n",
      "y shape: (3660, 49)\n",
      "Vocabulary of characters: 49\n"
     ]
    }
   ],
   "source": [
    "#X shape: 3D tensor. First dimension is the sentences, second is each letter in each sentence, third is the onehot\n",
    "#vector representing that letter.\n",
    "X = np.zeros((len(sentences), maxlen, vocabulary_size), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), vocabulary_size), dtype=np.bool)\n",
    "    \n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "    \n",
    "print(\"Done preparing training corpus, shapes of sets are:\")\n",
    "print(\"X shape: \" + str(X.shape))\n",
    "print(\"y shape: \" + str(y.shape))\n",
    "print(\"Vocabulary of characters:\", vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model\n",
    "\n",
    "- Model has one hidden layer of 128 LSTM cells.\n",
    "- Output layer uses the \"softmax\" activation function to output a probability distribution over next letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"figures/n-in-1-out.png\",width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO: Cut out of skeleton.\n",
    "\n",
    "layer_size = 128\n",
    "# build the model: a single LSTM\n",
    "model_train = Sequential()\n",
    "\n",
    "model_train.add(LSTM(layer_size, input_shape=(maxlen, len(chars))))\n",
    "# Project back to vocabulary. One output node for each letter.\n",
    "# Dense indicates a fully connected layer.\n",
    "# Softmax activation ensures the combined values of all outputs form a probability distribution:\n",
    "# They sum to 1, with each individual value between 0 and 1.\n",
    "model_train.add(Dense(len(chars), activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               91136     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 49)                6321      \n",
      "=================================================================\n",
      "Total params: 97,457\n",
      "Trainable params: 97,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Categorical crossentropy  minimizes the distance between the probability distributions \n",
    "# output by the network and the true distribution of the targets.\n",
    "# The optimizer specifies HOW the gradient of the loss will be used to update parameters.\n",
    "# Different optimizers have different tricks to avoid local optima, etc.\n",
    "# RMSProp is adaptive, adjusting the rate of learning to how fast we're currently learning.\n",
    "# Choose one by experimenting, or selecting one documented to work well for this problem by other researchers.\n",
    "model_train.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "model_train.summary()\n",
    "\n",
    "# LSTM is more complicated than the basic RNN we introduced. It has more free parameters, therefore more parameters \n",
    "# than one might expect below. We use them since they are better at learning long-term structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"figures/reweighting.png\",width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Sampling function - maybe keep this in skeleton?\n",
    "\n",
    "#Higher diversity -> more randomness in the generation.\n",
    "def sample(probability_distribution, diversity=1.0):\n",
    "    # helper function to sample an index from a probability distribution\n",
    "    probability_distribution = np.asarray(probability_distribution).astype('float64')\n",
    "    probability_distribution = np.log(probability_distribution) / diversity\n",
    "    exp_preds = np.exp(probability_distribution)\n",
    "    probability_distribution = exp_preds / np.sum(exp_preds)\n",
    "    #Draws 1 element at random according to the new scaled probability-distribution.\n",
    "    probabilities = np.random.multinomial(n=1, pvals = probability_distribution) \n",
    "    return np.argmax(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Method for printing some example text after every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_text_segment(length, diversity, generating_model = model_train, input_sequence_length = maxlen):\n",
    "    start_index = random.randint(0, len(text) - input_sequence_length - 1)\n",
    "\n",
    "    # We need a seed to start the text generation. Since during training the ANN always experiences\n",
    "    # sentences of size 30, we seed it with a sentence of length 30 to get it into a sensible state.\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + input_sequence_length]\n",
    "    generated += sentence\n",
    "    \n",
    "    sys.stdout.write('----- Generating with seed: \"' + sentence + '\"')\n",
    "\n",
    "    for i in range(length):\n",
    "        x_pred = np.zeros((1, input_sequence_length, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "        \n",
    "\n",
    "        predictions_distribution = generating_model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(predictions_distribution, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        #Stepping one symbol forward in the sentence\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    for diversity in [0.5]:#[0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = generate_text_segment(400, diversity, model_train, input_sequence_length = maxlen)\n",
    "        sys.stdout.write(generated)\n",
    "        print()\n",
    "        \n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training\n",
    "\n",
    "- Train on batches of 128 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" crossing\n",
      "judgment\n",
      "horizon\n",
      "the\" crossing\n",
      "judgment\n",
      "horizon\n",
      "the e re o scr at t ernr ae\n",
      "\n",
      " tcin\n",
      " eo har p   h srreerniaih ia  reifc trg el  iaeate ethreet  hone ra  r  ran   \n",
      "t r ia\n",
      "rar orr n rmr or ohc \n",
      "rerrararaateee rto hea\n",
      " te e  t tn enrrronentoeottere  rt  rhr ire eeceeoa n reas ee  h r\n",
      "aar i\n",
      "crteettra o ai e  re\n",
      "t \n",
      "totoe\n",
      "eert o eino  ehat areeneero\n",
      " a  r \n",
      " ar\n",
      "re   aaarr\n",
      "oearee eh n ar  e r  ri nu  tt tatn\n",
      " ht e  oa ird n   r  \n",
      "ar on e  nehec e e vece te\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"i\n",
      "past prologue\n",
      "a man alone\n",
      "ba\"i\n",
      "past prologue\n",
      "a man alone\n",
      "bartor tee tel lrr iirl t ot e rt eecorereo cor\n",
      "taret e t rde oorgort eter\n",
      "tor\n",
      "ooro ooret rorerir\n",
      "the bere rir t p otede bot t oncorortte\n",
      "tore\n",
      "enlore\n",
      "\n",
      "oetre t mort er\n",
      "o\n",
      "t toorre ohere the tho ror dor\n",
      "te\n",
      "o\n",
      "t o the\n",
      "the pore e oor the the oerd too t f c lert re t\n",
      "role tare deree oeremotor\n",
      "ereot eogercort\n",
      "seo\n",
      "t oor\n",
      "the le\n",
      "trdert ore ior d t e\n",
      "rorter\n",
      "t ord ter odeore t ettom oor\n",
      " ert cor e thedo \n",
      "the ter\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"cator\n",
      "singularity\n",
      "vanishing po\"cator\n",
      "singularity\n",
      "vanishing port ter\n",
      "dont escoron bolc une the dost ard\n",
      "the the tar time the son\n",
      "the ion\n",
      "the ne tarn rare\n",
      "tary \n",
      "lorthe\n",
      "wor\n",
      "the toe ant afa the \n",
      "are der\n",
      "the lort ond\n",
      "the tortar\n",
      "thetton\n",
      "the tal therde the port oat one\n",
      "the coar\n",
      "thi the the tenthe dort on tort the tonveytont part ror\n",
      "the we the the tare oor\n",
      "t\n",
      "cartiild\n",
      "the ad on\n",
      "the tort ont the dore wort ist wod\n",
      "of dart of \n",
      "wor\n",
      "the porortle thor\n",
      "of  he comdar\n",
      "the l\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"d, part ii\n",
      "things past\n",
      "warlord\"d, part ii\n",
      "things past\n",
      "warlordinse\n",
      "the part oneed\n",
      "shecaroneconcergakt actor\n",
      "the of antlendeer\n",
      "thire\n",
      "cionteridiparnat pare part artive part on\n",
      "the in\n",
      "the s\n",
      "ctarter\n",
      "the partiin\n",
      "the parter\n",
      "the or\n",
      "dhe parges\n",
      "the onthiunt\n",
      "iire\n",
      "fhine of cartire\n",
      "the part ort part on\n",
      "the parenor the if it eade\n",
      "the pore pare biret of se pare artirt ces\n",
      "feres\n",
      "thes\n",
      "the prree\n",
      "the parg parater\n",
      "the of the toontere part sis\n",
      "\n",
      "ire\n",
      "ere\n",
      "the intirethe part if in \n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ance man\n",
      "endgame\n",
      "broken bow\n",
      "fi\"ance man\n",
      "endgame\n",
      "broken bow\n",
      "five the parthe derthe certhe the parthe ane\n",
      "the unrcart en\n",
      "the blonce tart and\n",
      "the port marcaretthe sortteve part deemone\n",
      "the farter lirt the part en\n",
      "the arensthe darterken\n",
      "the dart dart bart lares\n",
      "the erathe part ennthe part on\n",
      "the tart ond of of the part an\n",
      "sturler\n",
      "she bart tire parcordince the part end are part in the vercelald the lar ser of the the the part indterathe mortecs\n",
      "inrerrrcen\n",
      "the al\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e needle\n",
      "visionary\n",
      "ex post fac\"e needle\n",
      "visionary\n",
      "ex post fact one\n",
      "the ofothe part if badd, (part in\n",
      "the the the part is\n",
      "the barcaddert part on\n",
      "shers\n",
      "the of horiseace cart on\n",
      "the haus inte\n",
      "the bacate of the part e\n",
      "the baracofesconma parc atce pagt in\n",
      "the sard dart the part it part on\n",
      "the part on\n",
      "daatee\n",
      "the the part of ard the part the part ifey\n",
      "the the part on\n",
      "moreadithe of the seache baco antimare\n",
      "the ceact of worus part in of the the the part in wacthe pa\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"hain of command: part one\n",
      "chai\"hain of command: part one\n",
      "chaim\n",
      "simser\n",
      "the s ante mast\n",
      "of the mandon\n",
      "the part the part in\n",
      "ard bmis the part in\n",
      "ant if the ange ves sind engs\n",
      "the bepars\n",
      "and sathe\n",
      "be asthor\n",
      "the part in\n",
      "the part in\n",
      "the wals\n",
      "and sarrs\n",
      "the part the batr\n",
      "shives\n",
      "the baitars\n",
      "the mighe var part of times\n",
      "datrond\n",
      "simanc\n",
      "wacstign of fis and the part in\n",
      "the part in the part i\n",
      "the mand sor\n",
      "the part in\n",
      "the bay part tit dos of the mats\n",
      "s part bat of the ald\n",
      "\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"\n",
      "paradise lost (part 2)\n",
      "protot\"\n",
      "paradise lost (part 2)\n",
      "protot\n",
      "the madion\n",
      "the keag the moddinc\n",
      "the moale\n",
      "deate\n",
      "the seage fey\n",
      "the the part in\n",
      "the part the of the the shatke\n",
      "barel of ent ferkin\n",
      "sameng\n",
      "the demeng lathion\n",
      "sion\n",
      "the doang beyor\n",
      "the onte long 1e patt of the moat of the cong\n",
      "the ghe part in\n",
      "the onhe foine\n",
      "the deang wo fathon\n",
      "the fead the domon\n",
      "the gamand\n",
      "the mapart of the the deall of plith\n",
      "the bloll of of the deang 1fepact\n",
      "the meagh\n",
      "the feine\n",
      "the f\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"esters of triskelion\n",
      "a piece o\"esters of triskelion\n",
      "a piece of the meat of the sear\n",
      "the a were the are mor thin\n",
      "shond\n",
      "the geyal the mengact\n",
      "the of the are war the meres of the meres\n",
      "the mearr\n",
      "the meare fir the sear\n",
      "the ereace\n",
      "cove in the seer the mirat of the derrelith perit on\n",
      "the part on the gheacimel stir\n",
      "al the mever the daime\n",
      "the varisater\n",
      "time the part on the gamer the serres\n",
      "of the part on firr the eny\n",
      "the coustrr\n",
      "the mear\n",
      "the boritroncer\n",
      "the part li\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"erpent's tooth\n",
      "the counter-clo\"erpent's tooth\n",
      "the counter-clon of of wactle of alt 1alor ard of the part of athe of thend ard leac ard datle\n",
      "the ander\n",
      "the dountion\n",
      "and the deagh\n",
      "the porcale\n",
      "the placegatr\n",
      "sencond\n",
      "artir\n",
      "the demend, part i\n",
      "figate\n",
      "the part of ald in\n",
      "the beatin\n",
      "the meadd stcrnthe\n",
      "the perat of the part on\n",
      "ar\n",
      "the viy ald on wire\n",
      "the wistine of ald mecand\n",
      "deate\n",
      "the magund\n",
      "the kead\n",
      "the deard of fitt of bacthe of the bay\n",
      "the legall of batton\n",
      "the bead\n",
      "\n",
      "----- Generating text after Epoch: 10\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e of angels (part 2)\n",
      "year of h\"e of angels (part 2)\n",
      "year of he\n",
      "the beate\n",
      "the veniin\n",
      "ance of the conde of the part on\n",
      "temand\n",
      "the weankent he the wond of wevinn of thendine\n",
      "wond ant ont stive\n",
      "the mand enter\n",
      "the encand on the cond\n",
      "stendenen\n",
      "the banatron\n",
      "mestrre\n",
      "the parntenthen\n",
      "part inten\n",
      "the angement on tend\n",
      "attenn enn\n",
      "tenent menifat\n",
      "wovence\n",
      "the palllive part twend\n",
      "shenter\n",
      "the munnd bnge\n",
      "the ancendons on tine\n",
      "in the angenenten\n",
      "encegation\n",
      "part in\n",
      "the anternter\n",
      "\n",
      "\n",
      "----- Generating text after Epoch: 11\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"\n",
      "bar association\n",
      "death wish\n",
      "li\"\n",
      "bar association\n",
      "death wish\n",
      "light of the the coust se\n",
      "cough se part on care io the wold ss\n",
      "dear the us of kithe the magal the sind\n",
      "sterestive cone\n",
      "the deyes of high\n",
      "steen part deecis\n",
      "in edes selle moud\n",
      "the monge sooke sorce\n",
      "the enien\n",
      "maghers\n",
      "couge of the poode part on\n",
      "the deal if the deesco\n",
      "tue porst sous lal sight of the mande of the mandes of the star\n",
      "the lighe soos firenien\n",
      "the pays\n",
      "the coud ball bigion\n",
      "the parle sove\n",
      "gold\n",
      "\n",
      "\n",
      "----- Generating text after Epoch: 12\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"unification: part one\n",
      "unificat\"unification: part one\n",
      "unificat part 1)\n",
      "unci\n",
      "the wonge hossang\n",
      "the couss\n",
      "fith\n",
      "time\n",
      "the condes\n",
      "shise\n",
      "the starce\n",
      "the wonde forstin\n",
      "the mand of time\n",
      "the uf the deact\n",
      "the in the mags\n",
      "inda beath\n",
      "of the lostine\n",
      "coust of tho wors of bitho\n",
      "the wosstimd\n",
      "shind\n",
      "the the porst of the lotlo\n",
      "fors\n",
      "stine\n",
      "the bar\n",
      "the cond the mend sole\n",
      "destine\n",
      "urstive\n",
      "stive\n",
      "conde and the deact\n",
      "the couss\n",
      "fothit\n",
      "the scand\n",
      "the unithe sorve\n",
      "timencand\n",
      "the mad\n",
      "the hou\n",
      "\n",
      "----- Generating text after Epoch: 13\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ry\n",
      "azati prime\n",
      "damage\n",
      "the forg\"ry\n",
      "azati prime\n",
      "damage\n",
      "the forger\n",
      "arcever\n",
      "the coudd ancemane of angeremederadove enden\n",
      "ches of the veall of withe sondis\n",
      "the wiond ance\n",
      "the coudd sichond\n",
      "the veaccs\n",
      "braterer\n",
      "the deance, part i\n",
      "all ghondere\n",
      "the beastive\n",
      "coustice\n",
      "the cart of ar evin\n",
      "cheld sichind\n",
      "recerser\n",
      "the child in the part on\n",
      "warke\n",
      "the coussin choun part i\n",
      "part catrone\n",
      "the mpars of star\n",
      "the ancight of the stind\n",
      "ancement of the sean\n",
      "chill vil the deach\n",
      "the man\n",
      "\n",
      "----- Generating text after Epoch: 14\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"'mach in all the wrong places\n",
      "\"'mach in all the wrong places\n",
      "mater\n",
      "the unithe monge of the scare if the couds of the dear\n",
      "the dearcenter\n",
      "the manas of the part on\n",
      "the cost of the part in\n",
      "the doescord\n",
      "s\n",
      "the arencencance\n",
      "cove repactides\n",
      "arg the deerg intencerce\n",
      "dears\n",
      "are the ence of the veatr\n",
      "stee sous of an-inis in a (opr\n",
      "the enis in arcatres ance manare\n",
      "hewrendive\n",
      "tore shances\n",
      "the couds\n",
      "shis and stare of the starion\n",
      "the enee of the scadcerdor darate\n",
      "the ecan\n",
      "\n",
      "----- Generating text after Epoch: 15\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ttle\n",
      "captive pursuit\n",
      "aquiel\n",
      "q-\"ttle\n",
      "captive pursuit\n",
      "aquiel\n",
      "q-gation\n",
      "farestar\n",
      "the magation\n",
      "mect tho us of the ploper\n",
      "the douse\n",
      "store of the shald\n",
      "stead of the behold\n",
      "the plopente\n",
      "coure of the plattty\n",
      "the beath\n",
      "blouds of the platht of the adoine\n",
      "deyplat (part 1)\n",
      "pletity\n",
      "brofece\n",
      "tre ne and silate\n",
      "bratllle of hight of the plipe\n",
      "the blatht of the wredores of the letront of the dear\n",
      "the parse\n",
      "cals of matre beht the porte\n",
      "the soudd of and and ey ang the woplloun a\n",
      "\n",
      "----- Generating text after Epoch: 16\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"\n",
      "a man alone\n",
      "babel\n",
      "ship in a b\"\n",
      "a man alone\n",
      "babel\n",
      "ship in a bart i)\n",
      "gamall sen\n",
      "the thine\n",
      "the parat\n",
      "waldos\n",
      "the waycenter\n",
      "the mend shight of the part i\n",
      "parkige\n",
      "viospore\n",
      "dapale beate\n",
      "the portto\n",
      "lof thongn mor\n",
      "once\n",
      "cond of horce\n",
      "the cofd\n",
      "the part on\n",
      "wous anse part i\n",
      "part once sind\n",
      "in thougstive\n",
      "dopale\n",
      "copat\n",
      "the bay\n",
      "sthon\n",
      "the parst part i\n",
      "pars inten\n",
      "the uminn\n",
      "the manden dorks\n",
      "sourd sury\n",
      "the mond shoplonce\n",
      "cond of the part on\n",
      "plorestar\n",
      "domend\n",
      "secall deavi\n",
      "bald of\n",
      "\n",
      "----- Generating text after Epoch: 17\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"els (part 2)\n",
      "year of hell, par\"els (part 2)\n",
      "year of hell, part i\n",
      "ehor marsange of the blats\n",
      "the mandes on wish\n",
      "raterer\n",
      "dovios, part i\n",
      "fars and ser\n",
      "the gring\n",
      "the parthine\n",
      "sivengirm\n",
      "the placous the plophote\n",
      "duess\n",
      "are on allign warrentin choro sorss and star\n",
      "stiveorl rrtign\n",
      "res on carckin\n",
      "cofstive\n",
      "stirrarion\n",
      "dears\n",
      "factice\n",
      "conde bay\n",
      "logallis\n",
      "the ancend\n",
      "rivion\n",
      "chill ancet on ar ance and silation\n",
      "matarere\n",
      "the parturs\n",
      "scoverrine of the para is ance\n",
      "condaly\n",
      "sciven\n",
      "\n",
      "\n",
      "----- Generating text after Epoch: 18\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"nd prosper\n",
      "muse\n",
      "fury\n",
      "life line\"nd prosper\n",
      "muse\n",
      "fury\n",
      "life line\n",
      "the parat of the peape\n",
      "tee spars\n",
      "almege ancence, part i\n",
      "ea mome in the vight of the leado\n",
      "the peath\n",
      "inmenchive\n",
      "the perpilstur\n",
      "the parat (part 1)\n",
      "untide part d\n",
      "ente fatter of fit the vearr\n",
      "the weyal wofld part i)\n",
      "wral the plitht\n",
      "the the parter\n",
      "the mear\n",
      "the feat part in ic in the mead\n",
      "shokw\n",
      "shils\n",
      "als in the vieat of kitr\n",
      "the veacctive\n",
      "the beht deact\n",
      "the pary's in the parthon\n",
      "werctive\n",
      "stive\n",
      "are fatc\n",
      "\n",
      "----- Generating text after Epoch: 19\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ound of her voice\n",
      "tears of the\"ound of her voice\n",
      "tears of the starr's ente part in\n",
      "the coud silation\n",
      "part in\n",
      "the coudd and the mar's drive\n",
      "bold liok\n",
      "fre the manare forct\n",
      "enemarres of art ente of fat of enter\n",
      "the eriendor ale the andenge firithe ssichind\n",
      "revion\n",
      "invels\n",
      "the coude of the dear\n",
      "the magrerce\n",
      "cope\n",
      "the mand sarome\n",
      "doscare\n",
      "the mandenighe\n",
      "the koud ance\n",
      "coustive\n",
      "coustice\n",
      "conde alt geare fort of the prive\n",
      "tromendivi bas\n",
      "bloge\n",
      "woun mathon\n",
      "wovenge of the \n",
      "Training done\n"
     ]
    }
   ],
   "source": [
    "# Training the Model. history captures data for plotting (e.g loss)\n",
    "# Kai: The default Keras \"progress bar\" made my notebook freeze. this keras-tqdm fixes that.\n",
    "# Installed with pip install keras-tqdm.\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "print(\"training start\")\n",
    "history = model_train.fit(X, y, batch_size=128, epochs=20, verbose=0, callbacks=[print_callback,TQDMNotebookCallback()])\n",
    "print(\"Training done\")\n",
    "#TODO: Ask Charles: Any motivation for this batch size? What does batch size mean exactly in this setting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save model if necessary\n",
    "model_train.save(\"keras-startrek-LSTM-model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Plotting training and validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhyPBJ/INm1QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f198cfd54e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Make a Decoder model\n",
    "\n",
    "During training, we presented sequences of 30 characters, along with the correct next character.\n",
    "When_using the trained model, it may be more useful to feed in 1 character at a time, and seeing the next\n",
    "predicted one. That will also convince us that the network is actually _using_ its internal state.\n",
    "\n",
    "- Needs input length of 1.\n",
    "- Needs batch size of 1\n",
    "- Needs LSTM to be stateful\n",
    "- check that params is the same as model_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"figures/1-in-1-out.png\",width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Load model if necessary.\n",
    "model_train = load_model(\"keras-startrek-LSTM-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build a decoding model (input length 1, batch size 1, stateful)\n",
    "layer_size = 128\n",
    "\n",
    "model_dec = Sequential()\n",
    "# 1 letter in, 1 letter out.\n",
    "# Stateful=True keeps the state from the end of one batch to the start of the next\n",
    "# In other words, the network \"remembers\" its state from one input to the next. This is essential when\n",
    "# the network looks at 1 input at a time.\n",
    "model_dec.add(LSTM(layer_size, stateful=True, batch_input_shape=(1,1,len(chars))))\n",
    "\n",
    "# project back to vocabulary\n",
    "model_dec.add(Dense(vocabulary_size, activation='softmax'))\n",
    "model_dec.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "model_dec.summary()\n",
    "\n",
    "# set weights from training model\n",
    "# Note that we can reuse these weights, since the sizes of the trained and decoder network are the same.\n",
    "# The trained network took in 30 characters, but remember that all these 30 used the same input weights.\n",
    "# That is one of the advantages of RNNs: They are independent of sequence lengths.\n",
    "model_dec.set_weights(model_train.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test the Model\n",
    "\n",
    "- Take a quote then add 400 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Sample 1000 characters from the decoding model using a random seed from the vocabulary.\n",
    "generated = generate_text_segment(1000, diversity=0.5, generating_model = model_dec, input_sequence_length = 1)\n",
    "sys.stdout.write(generated)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "68a0903c8cb44d7f844576a9e191a074": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "73196c60cb1f4fa1a36a9200fb5ec526": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    },
    "75ed5e35093c4569af70d449c8d599dd": {
     "views": [
      {
       "cell_index": 18
      }
     ]
    },
    "aa7bb86c093a47a48ddd69380fe4d1b1": {
     "views": [
      {
       "cell_index": 17
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
