{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character Level RNN using LSTM cells.\n",
    "\n",
    "- Trains on Star Trek episode titles\n",
    "- Outputs \"fake\" titles.\n",
    "\n",
    "Much comes from a [Keras example](https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py).\n",
    "\n",
    "## Setup Environment\n",
    "\n",
    "- Import Keras\n",
    "- Open up the Star Trek corpus\n",
    "- We need to translate the textual data into a format that the RNN can accept as input.\n",
    "- Give each letter an index and create dictionaries to translate from index to character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 11017\n",
      "total chars: 52\n",
      "Max: 50\n",
      "Mean: 14.010899182561309\n",
      "Median: 13.0\n",
      "Min: 2\n",
      "Character Dictionary:  {'\\n': 0, ' ': 1, '!': 2, \"'\": 3, '(': 4, ')': 5, ',': 6, '-': 7, '.': 8, '0': 9, '1': 10, '2': 11, '3': 12, '4': 13, '5': 14, '7': 15, '8': 16, '9': 17, ':': 18, '?': 19, 'a': 20, 'b': 21, 'c': 22, 'd': 23, 'e': 24, 'f': 25, 'g': 26, 'h': 27, 'i': 28, 'j': 29, 'k': 30, 'l': 31, 'm': 32, 'n': 33, 'o': 34, 'p': 35, 'q': 36, 'r': 37, 's': 38, 't': 39, 'u': 40, 'v': 41, 'w': 42, 'x': 43, 'y': 44, 'z': 45, '\\xa0': 46, '©': 47, 'â': 48, 'ã': 49, '€': 50, '™': 51}\n",
      "Inverse Character Dictionary:  {0: '\\n', 1: ' ', 2: '!', 3: \"'\", 4: '(', 5: ')', 6: ',', 7: '-', 8: '.', 9: '0', 10: '1', 11: '2', 12: '3', 13: '4', 14: '5', 15: '7', 16: '8', 17: '9', 18: ':', 19: '?', 20: 'a', 21: 'b', 22: 'c', 23: 'd', 24: 'e', 25: 'f', 26: 'g', 27: 'h', 28: 'i', 29: 'j', 30: 'k', 31: 'l', 32: 'm', 33: 'n', 34: 'o', 35: 'p', 36: 'q', 37: 'r', 38: 's', 39: 't', 40: 'u', 41: 'v', 42: 'w', 43: 'x', 44: 'y', 45: 'z', 46: '\\xa0', 47: '©', 48: 'â', 49: 'ã', 50: '€', 51: '™'}\n"
     ]
    }
   ],
   "source": [
    "## Much borrowed from https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.callbacks import LambdaCallback\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "#Helper method sampling and generating text from an RNN after training\n",
    "from SamplingAndGeneratingText import generate_text_segment\n",
    "\n",
    "text = open(\"startrekepisodes.txt\").read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocabulary_size = len(chars)\n",
    "print('total chars:', vocabulary_size)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "\n",
    "# How long is a title?\n",
    "titles = text.split('\\n')\n",
    "lengths = np.array([len(n) for n in titles])\n",
    "print(\"Max:\", np.max(lengths))\n",
    "print(\"Mean:\", np.mean(lengths))\n",
    "print(\"Median:\", np.median(lengths))\n",
    "print(\"Min:\", np.min(lengths))\n",
    "\n",
    "# hence choose 30 as seuence length to train on.\n",
    "print(\"Character Dictionary: \", char_indices)\n",
    "print(\"Inverse Character Dictionary: \", indices_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Training Data\n",
    "\n",
    "- Cut up the corpus into semi-redundant sequences of 30 characters.\n",
    "- Change indices into \"one-hot\" vector encodings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/slicing_text.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 3663\n",
      "the man trap\n",
      "charlie x\n",
      "where n\n",
      "o\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 30\n",
    "step = 3\n",
    "\n",
    "sentences = [] #The training data\n",
    "next_chars = [] #The training labels\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    \n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print(sentences[0])\n",
    "print(next_chars[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Onehot encoding:\n",
    "* a -> [1, 0, 0, ..., 0]\n",
    "* b -> [0, 1, 0, ..., 0]\n",
    "* ...\n",
    "\n",
    "Each training sample becomes 2D tensor:\n",
    "* \"This is the text\" -> X = [[0, 0, ..., 1, 0, ..., 0], ..., [0, 0, ..., 1, 0, ... 0]]\n",
    "\n",
    "Each target (next letter) becomes 1D onehot tensor:\n",
    "* a -> y = [1, 0, 0, ..., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done preparing training corpus, shapes of sets are:\n",
      "X shape: (3663, 30, 52)\n",
      "y shape: (3663, 52)\n",
      "Vocabulary of characters: 52\n"
     ]
    }
   ],
   "source": [
    "#X shape: 3D tensor. First dimension is the sentences, second is each letter in each sentence, third is the onehot\n",
    "#vector representing that letter.\n",
    "X = np.zeros((len(sentences), maxlen, vocabulary_size), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), vocabulary_size), dtype=np.bool)\n",
    "    \n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "    \n",
    "print(\"Done preparing training corpus, shapes of sets are:\")\n",
    "print(\"X shape: \" + str(X.shape))\n",
    "print(\"y shape: \" + str(y.shape))\n",
    "print(\"Vocabulary of characters:\", vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "- Model has one hidden layer of 128 LSTM cells.\n",
    "- Output layer uses the \"softmax\" activation function to output a probability distribution over next letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/n-in-1-out.png\" width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_size = 128\n",
    "model_train = Sequential()\n",
    "model_train.add(LSTM(layer_size, input_shape=(maxlen, len(chars))))\n",
    "# Project back to vocabulary. One output node for each letter.\n",
    "# Dense indicates a fully connected layer.\n",
    "# Softmax activation ensures the combined values of all outputs form a probability distribution:\n",
    "# They sum to 1, with each individual value between 0 and 1.\n",
    "model_train.add(Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               92672     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 52)                6708      \n",
      "=================================================================\n",
      "Total params: 99,380\n",
      "Trainable params: 99,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Categorical crossentropy  minimizes the distance between the probability distributions \n",
    "# output by the network and the true distribution of the targets.\n",
    "# The optimizer specifies HOW the gradient of the loss will be used to update parameters.\n",
    "# Different optimizers have different tricks to avoid local optima, etc.\n",
    "# RMSProp is adaptive, adjusting the rate of learning to how fast we're currently learning.\n",
    "model_train.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "model_train.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "- Train on batches of 128 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callback, which starts some text generation after each epoch.\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    diversity = 0.5 #Can be modified to change the amount of creativity in the network\n",
    "\n",
    "    generated = generate_text_segment(text, 400, diversity, model_train,\n",
    "                                      maxlen, len(chars), char_indices, indices_char)\n",
    "    sys.stdout.write(generated)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \"litude\n",
      "carpenter street\n",
      "chosen\"litude\n",
      "carpenter street\n",
      "chosenn ahahitiis  ahr e arao iit  a hg  os \n",
      "a\n",
      " aaaiie s \n",
      " ahrt r\n",
      " ha k he hi  ao iase\n",
      " asihai \n",
      "aae s \n",
      "iaioaa esasn of oia lhrih e ssarose neoh riasaiie   ie et\n",
      "a h  nd oie ah nok airr s aiaa\n",
      " \n",
      " ahahe hoo sthe  ahe hhheihitai  h e   siso\n",
      "s hediis   hi sha an  hthiatiiiheiiesieai  hhare asaar tnii ai\n",
      "asa aaa\n",
      "ta hate ayh he  a \n",
      " tiac esait \n",
      "rat aahho ha i ari  ee aaahs\n",
      " olaia  i ai st\n",
      " rh ss  a.iasha i he\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \"ion\n",
      "the terratin incident\n",
      "the \"ion\n",
      "the terratin incident\n",
      "the wortsi\n",
      "cintantorerithongwrrt\n",
      "thers\n",
      "wer\n",
      "the shironatherthe thin\n",
      "inlens\n",
      "che sirinshr\n",
      "mhertherthern he kar\n",
      "larthirthinthe phe therthertthe therorrasthirt therthes\n",
      "che thertirs\n",
      "farche fert\n",
      "the tien\n",
      "theringsitinergrinir\n",
      "1rlin\n",
      "inches\n",
      "cormoricher chinthertherganens\n",
      "thor the sve sin frrthe thinrpdan\n",
      "bern\n",
      "qare nermais\n",
      "nar\n",
      "the dar\n",
      "sher\n",
      "therpantherttarcohirtentherthe arsnr\n",
      "thin\n",
      "the paran\n",
      "thrrthe\n",
      "cerisyr\n",
      "heng\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \"r\n",
      "facets\n",
      "the adversary\n",
      "the 37'\"r\n",
      "facets\n",
      "the adversary\n",
      "the 37's\n",
      "ent\n",
      "the flend\n",
      "che bad heshe he e\n",
      "the port on e cant anthe anereraril\n",
      "the nothe ongesind sh\n",
      "shesas an antililhe or the dire onthe lale\n",
      "darthe he hesink\n",
      "shereinn\n",
      "she antire onirt ant ont e\n",
      "dar\n",
      "\n",
      "the he ine\n",
      "ere\n",
      "the al ens\n",
      "part shetare\n",
      "she herin\n",
      "sor anthe anthe anthe whens\n",
      "the he he farthesherer onser\n",
      "the sises\n",
      "nd rarer bomarst\n",
      "mane\n",
      "the tart\n",
      "baress\n",
      "she ouse sas\n",
      "anthe andis orthe ind\n",
      "the parthe here\n",
      "t\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \"st\n",
      "where no one has gone befor\"st\n",
      "where no one has gone beforiletire\n",
      "the the the the coantiid\n",
      "che the dort one wort olere fire the the bereri\n",
      "the borelingortint ilige\n",
      "the rerile shengorthe the the certhe thi the tart therthe antirine lore corenane part oigere\n",
      "the the iortirtiintint\n",
      "the seran\n",
      "the part the the fart of fontition\n",
      "thens\n",
      "the core iing\n",
      "the veterile merotheroinicetire\n",
      "tartinteroci\n",
      "the thepgenging she the wict one lint oof werer iosthe core one\n",
      "the \n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \"pion, part ii\n",
      "the gift\n",
      "day of \"pion, part ii\n",
      "the gift\n",
      "day of ond\n",
      "the ses\n",
      "sust\n",
      "\n",
      "igesh parl\n",
      "wage\n",
      "ris\n",
      "the tion\n",
      "s\n",
      "the deri\n",
      "tion\n",
      "the sion\n",
      "the sess\n",
      "bling\n",
      "the goge\n",
      "the gale\n",
      "the doge\n",
      "the dare\n",
      "the ve on\n",
      "the ale\n",
      "coris\n",
      "the siag\n",
      "se\n",
      "chess\n",
      "whis\n",
      "shime\n",
      "bome\n",
      "sals on\n",
      "the ing\n",
      "bos\n",
      "chiine\n",
      "lice\n",
      "bollon\n",
      "the sher\n",
      "boco\n",
      "shonce\n",
      "sherble\n",
      "tion\n",
      "the sorcan\n",
      "the gori\n",
      "the part\n",
      "risi\n",
      "cous\n",
      "bes\n",
      "the dot in\n",
      "tho gort\n",
      "the this\n",
      "are\n",
      "chork\n",
      "the \n",
      "iniin\n",
      "the sige\n",
      "the woli\n",
      "the kinge\n",
      "blobl\n",
      "shons\n",
      "the sithis\n",
      "si\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- Generating with seed: \"of the prophets\n",
      "image in the s\"of the prophets\n",
      "image in the siins\n",
      "par al the ining\n",
      "shegin\n",
      "the couk\n",
      "the riles\n",
      "in ind of rong\n",
      "the fiond fa tion\n",
      "thilli\n",
      "the the the das of the the coint on ent of dile\n",
      "codss\n",
      "the gaok\n",
      "blemon\n",
      "the niem\n",
      "the foand of louy\n",
      "the lint\n",
      "thi geor\n",
      "moond of tho blolis\n",
      "the liok\n",
      "woinst\n",
      "colilis sear\n",
      "the siak\n",
      "daad of inging\n",
      "coom of of the sis an\n",
      "the cook\n",
      "dames of hond\n",
      "the fooding the the sion\n",
      "arel\n",
      "the ane the e of loars\n",
      "in mang of dames on dis\n",
      "se\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- Generating with seed: \"use (part 1)\n",
      "heroes and demons\"use (part 1)\n",
      "heroes and demons\n",
      "the oue sion\n",
      "bore\n",
      "surunt\n",
      "ches\n",
      "line\n",
      "brors\n",
      "the bouter\n",
      "tare corser\n",
      "the leste sior\n",
      "the the the bintick\n",
      "the blole the bole be the and less ant on\n",
      "the be the ine the of the linger\n",
      "the werre\n",
      "beare\n",
      "the lese part one\n",
      "cour of wore\n",
      "the meart\n",
      "wero enile\n",
      "wint\n",
      "cers or the the the heyad the dere\n",
      "werate ter\n",
      "the fbrblere\n",
      "the the blore\n",
      "the botak\n",
      "the besile\n",
      "the bleul the the bllone\n",
      "the leqte atter\n",
      "the the the lome\n",
      "\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- Generating with seed: \"isition\n",
      "attached\n",
      "necessary evi\"isition\n",
      "attached\n",
      "necessary evily\n",
      "the the ble cors\n",
      "meart\n",
      "the sarse spartion\n",
      "the salily\n",
      "rolllithe sart\n",
      "intick\n",
      "coussise\n",
      "shirnd cast\n",
      "chily\n",
      "ind forte of part of gols\n",
      "ermens\n",
      "the mantion\n",
      "the rougr of angico\n",
      "dart fartion\n",
      "the sess\n",
      "shessant\n",
      "the sagror\n",
      "park of enti\n",
      "the mesil\n",
      "the dand werbly\n",
      "the waris\n",
      "the desily\n",
      "the mane\n",
      "the all\n",
      "the manking\n",
      "chily\n",
      "the siss\n",
      "allay\n",
      "shire of and of gowasy\n",
      "couss\n",
      "the wary\n",
      "daulless\n",
      "the warn int of hill\n",
      "the sart\n",
      "t\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- Generating with seed: \"\n",
      "the host\n",
      "the mind's eye\n",
      "in th\"\n",
      "the host\n",
      "the mind's eye\n",
      "in the betares\n",
      "demend ald er\n",
      "the fountimene\n",
      "beartemant inge of ale of the nese\n",
      "baut ine dayter\n",
      "eha mane searne siinge ana autine\n",
      "brof and the surrenine\n",
      "buure\n",
      "bant ere sior\n",
      "reart of desadecers\n",
      "the daage of wernor healce\n",
      "shesing\n",
      "the lesulo\n",
      "banthe endence\n",
      "sheable boke the dare\n",
      "bomonter\n",
      "the dager\n",
      "the ale of audice\n",
      "bate mare\n",
      "budmen and parten\n",
      "beal abokice\n",
      "bounter\n",
      "weabin ene ouser\n",
      "sime\n",
      "the betector\n",
      "butere on\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- Generating with seed: \"et motive\n",
      "eye of the needle\n",
      "vi\"et motive\n",
      "eye of the needle\n",
      "vive of the forgation\n",
      "the ancigenan\n",
      "the list\n",
      "fring\n",
      "the shaghis\n",
      "the mishor, part i\n",
      "thiss\n",
      "shild\n",
      "the siond of hist on dest\n",
      "prind\n",
      "the forgol\n",
      "the disting\n",
      "the singar\n",
      "the bowk\n",
      "shint\n",
      "fhrond\n",
      "the hige\n",
      "shight sar\n",
      "\n",
      "eof fichole\n",
      "the mogrlon\n",
      "prondyedinis\n",
      "pronding\n",
      "the fire\n",
      "bond par dion\n",
      "the mogrodion\n",
      "propay\n",
      "loses frint the sing\n",
      "dãomparnitiving\n",
      "cold of the lisa\n",
      "hand of dirgor, part ii\n",
      "the shaghe stant of the blong p\n",
      "\n",
      "----- Generating text after Epoch: 10\n",
      "----- Generating with seed: \"art of glory\n",
      "the arsenal of fr\"art of glory\n",
      "the arsenal of fresh of athime\n",
      "bomane of fort\n",
      "and tamo\n",
      "shecons of hesily\n",
      "eniin\n",
      "the mand of and of the das a siss\n",
      "andis ant the couss\n",
      "dess\n",
      "shand of athiss\n",
      "axsions of ent\n",
      "remona inive shili\n",
      "e sage moncoss one\n",
      "the fart of and camession\n",
      "dears on deant\n",
      "derdle af and the the sharhion\n",
      "the mand\n",
      "shenand of and domane of holl\n",
      "boll of the bold of hold\n",
      "comreant on allons\n",
      "the moge of hegr pars\n",
      "buge sqare of monoly\n",
      "the fart and\n",
      "\n",
      "----- Generating text after Epoch: 11\n",
      "----- Generating with seed: \"\n",
      "the chute\n",
      "the swarm\n",
      "apocalyps\"\n",
      "the chute\n",
      "the swarm\n",
      "apocalypss of demoni\n",
      "carboned of thes shery\n",
      "the bepters ars orher\n",
      "eresions\n",
      "shemenatime\n",
      "shirkion\n",
      "the meqreringes\n",
      "the veys\n",
      "the pearthos\n",
      "she forghter\n",
      "the the chise\n",
      "the lome\n",
      "erish\n",
      "part ii\n",
      "the uine\n",
      "wartion\n",
      "shestent\n",
      "the the ceallyon\n",
      "entire\n",
      "the boude\n",
      "mantion\n",
      "the meshor\n",
      "ant ois lome\n",
      "suresion\n",
      "the whathes\n",
      "artene\n",
      "the foudther\n",
      "destre\n",
      "the line\n",
      "bome wart oes\n",
      "memesion's\n",
      "mome\n",
      "apiin poistron\n",
      "the memanore\n",
      "coussas\n",
      "retereathe\n",
      "\n",
      "----- Generating text after Epoch: 12\n",
      "----- Generating with seed: \"sk\n",
      "treachery, faith, and the g\"sk\n",
      "treachery, faith, and the gomechil ce fare of the firgh on and dãathe starre, part ii\n",
      "the host partion\n",
      "the whand\n",
      "wers and dass\n",
      "past part wors\n",
      "bromes part oi\n",
      "the sqpiches of the ale ofiat\n",
      "sess the lise\n",
      "batking of carure of the sileco\n",
      "boutr part farcons\n",
      "shillans of the warkons\n",
      "brokions\n",
      "the manding\n",
      "leand of shary\n",
      "ex of the lish of the lose\n",
      "the alece in firatiok\n",
      "starmanivi\n",
      "the sqqurie\n",
      "sarinico sbine of and suring samentice\n",
      "shin\n",
      "\n",
      "----- Generating text after Epoch: 13\n",
      "----- Generating with seed: \"e needle\n",
      "visionary\n",
      "ex post fac\"e needle\n",
      "visionary\n",
      "ex post fact ois\n",
      "shiles and doss\n",
      "the siand\n",
      "the mome\n",
      "propicor par liond\n",
      "the searnion\n",
      "the dascons gror\n",
      "borbe of hilo\n",
      "boobbbe the gold an the be of erion\n",
      "child's and dadary\n",
      "ex of the shary\n",
      "ere forore\n",
      "the manday\n",
      "ex of kold\n",
      "breno\n",
      "batters\n",
      "the searnor, part ii\n",
      "propay\n",
      "rearn of voring\n",
      "dbagay\n",
      "exs on the deartion\n",
      "rete part ii\n",
      "the mond of the mond\n",
      "whalle starth se\n",
      "couster of holl\n",
      "bemont\n",
      "the blome\n",
      "the shary\n",
      "ere courn\n",
      "dea\n",
      "\n",
      "----- Generating text after Epoch: 14\n",
      "----- Generating with seed: \"balance of terror\n",
      "shore leave\n",
      "\"balance of terror\n",
      "shore leave\n",
      "shiles\n",
      "cartian\n",
      "the dayaly\n",
      "the parchis cors\n",
      "erility\n",
      "sholday\n",
      "the homble aghed\n",
      "carspice\n",
      "shise\n",
      "a tisp sca\n",
      "the sigrcon and the mage of achile\n",
      "bokont undis deart\n",
      "the ard cord\n",
      "borble fir the achis leagr\n",
      "una warilyig\n",
      "the shar\n",
      "aud ore thilese cartle gold fart ii\n",
      "the shark\n",
      "anc dars\n",
      "the sharker\n",
      "the shary\n",
      "the fayt tors and dãagar\n",
      "exs age of korisile\n",
      "the mage of boldous\n",
      "shiss\n",
      "and the firger\n",
      "doost the werrily\n",
      "e\n",
      "\n",
      "----- Generating text after Epoch: 15\n",
      "----- Generating with seed: \"minefield\n",
      "dead stop\n",
      "a night in\"minefield\n",
      "dead stop\n",
      "a night in\n",
      "the tise\n",
      "carbinici\n",
      "invililither\n",
      "hili\n",
      "hile\n",
      "inisian\n",
      "runecion\n",
      "the siind\n",
      "surino\n",
      "beminivisi\n",
      "caropiin the dist\n",
      "corcativis\n",
      "countini\n",
      "the the cigrbini\n",
      "the scadle of aperini\n",
      "henkililive and grordion\n",
      "pripatore\n",
      "the siary\n",
      "enfirntion\n",
      "prither\n",
      "corsearion\n",
      "the sisis\n",
      "infire\n",
      "the the bist\n",
      "cartine part ii\n",
      "thie mine\n",
      "the mistion\n",
      "the sililye of the lishi\n",
      "the the mistion\n",
      "the the gaydanct\n",
      "ercorne\n",
      "bauntice\n",
      "sherkian\n",
      "thex ins\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Generating text after Epoch: 16\n",
      "----- Generating with seed: \"akening\n",
      "kir'shara\n",
      "daedalus\n",
      "obs\"akening\n",
      "kir'shara\n",
      "daedalus\n",
      "obser af ich deage feqf dool\n",
      "susering\n",
      "the dist\n",
      "carconca of gombbetthe gr most the wester\n",
      "the the dead\n",
      "the sigh of the gisice\n",
      "the shary\n",
      "the shagario, gar dist\n",
      "the qwarce\n",
      "shencon\n",
      "the sing\n",
      "warion, part ii\n",
      "thiessice\n",
      "the sigrthe bisth the vise\n",
      "the alstrention\n",
      "the sqarh of gombed\n",
      "the sight friletof anctuncad\n",
      "combar distring\n",
      "dounth wos and the wearn\n",
      "bloft the gisis\n",
      "colbabthe lise\n",
      "brish of hegrt\n",
      "the sigr of \n",
      "\n",
      "----- Generating text after Epoch: 17\n",
      "----- Generating with seed: \"cargo\n",
      "nemesis\n",
      "the catwalk\n",
      "dawn\"cargo\n",
      "nemesis\n",
      "the catwalk\n",
      "dawn s surre\n",
      "shorbenang dougron\n",
      "part twoss\n",
      "semencorgant: sartion, part ii\n",
      "the sister of holl\n",
      "wealldos an torne\n",
      "shaday of the suring\n",
      "ousarn: sarsion\n",
      "propaced\n",
      "batakity\n",
      "sqsacr's part in\n",
      "the siandar, se of forca\n",
      "tirper\n",
      "the shary\n",
      "ex of the dougrons\n",
      "retread\n",
      "erongent\n",
      "urithe sqorna of ancan\n",
      "shidasaro\n",
      "whelace\n",
      "sqare on the dist\n",
      "resary\n",
      "erons seary\n",
      "erfant fronty\n",
      "the dountion\n",
      "thiless and parfirt: part of the deste\n",
      "\n",
      "----- Generating text after Epoch: 18\n",
      "----- Generating with seed: \"\n",
      "unexpected\n",
      "terra nova\n",
      "the and\"\n",
      "unexpected\n",
      "terra nova\n",
      "the and the ding\n",
      "sureation's one\n",
      "the ene\n",
      "retantect\n",
      "reaco, part ii\n",
      "the wernori\n",
      "iner a tite\n",
      "s pronting\n",
      "cortant\n",
      "twe longentri\n",
      "the wons dost\n",
      "turte se\n",
      "collent twenly\n",
      "brthint\n",
      "sart one fart ii\n",
      "the sing\n",
      "deaglalond fart ii\n",
      "chissagilise\n",
      "the ging\n",
      "surcoruin: part ii\n",
      "chissigr weare of gathe\n",
      "stactorse\n",
      "care of his of angiture\n",
      "the destr part ii\n",
      "the way of mombou\n",
      "the sige fightis\n",
      "reall of mombor\n",
      "the shis\n",
      "enal ans gond pa\n",
      "\n",
      "----- Generating text after Epoch: 19\n",
      "----- Generating with seed: \" earth\n",
      "spock's brain\n",
      "the enter\" earth\n",
      "spock's brain\n",
      "the entern\n",
      "the gand\n",
      "wenaly\n",
      "ens frise\n",
      "banati\n",
      "the ame\n",
      "reall of the parclys\n",
      "the whack\n",
      "nenaleri , part i\n",
      "the wayconage bnd and the list\n",
      "serspond fart tor\n",
      "the sagris\n",
      "infid the list\n",
      "surtion\n",
      "past tart\n",
      "the alsernation\n",
      "battice\n",
      "shonkant\n",
      "corcing wer\n",
      "lookbbin\n",
      "the starm\n",
      "int ore and\n",
      "carcling part\n",
      "the dist\n",
      "carbons part the lise\n",
      "cart one of vorice\n",
      "boftde th starman t mage of the prond cors\n",
      "hookman\n",
      "the ssarle of kogrod\n",
      "har\n",
      "Training done\n"
     ]
    }
   ],
   "source": [
    "# Training the Model. history captures data for plotting (e.g loss)\n",
    "print(\"training start\")\n",
    "#Setting up a callback, which will generate example text from the network during training.\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "history = model_train.fit(X, y, batch_size=128, epochs=20, verbose=0, callbacks=[print_callback])\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model if necessary\n",
    "model_train.save(\"keras-startrek-LSTM-model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting training and validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'b-o', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
