{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Character Level RNN using LSTM cells.\n",
    "\n",
    "- Trains on Star Trek episode titles\n",
    "- Outputs \"fake\" titles.\n",
    "\n",
    "Much comes from a [Keras example](https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py).\n",
    "\n",
    "## Setup Environment\n",
    "\n",
    "- Import Keras\n",
    "- Open up the Star Trek corpus\n",
    "- We need to translate the textual data into a format that the RNN can accept as input.\n",
    "- Give each letter an index and create dictionaries to translate from index to character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 11010\n",
      "total chars: 49\n",
      "Max: 50\n",
      "Mean: 14.001362397820163\n",
      "Median: 13.0\n",
      "Min: 2\n",
      "Character Dictionary:  {'\\n': 0, 'x': 43, 'a': 20, ' ': 1, 'e': 24, 'q': 36, '0': 9, '2': 11, '9': 17, 'u': 40, \"'\": 3, 'c': 22, 'r': 37, 'k': 30, 'é': 47, 'f': 25, '-': 7, '1': 10, '!': 2, '’': 48, 'd': 23, 'h': 27, '3': 12, '.': 8, 'o': 34, '(': 4, 'i': 28, 'b': 21, '7': 15, '4': 13, ')': 5, 'j': 29, 'v': 41, 'm': 32, 'g': 26, 'y': 44, 't': 39, 'à': 46, 'w': 42, 'l': 31, '?': 19, '8': 16, ':': 18, 'n': 33, 'p': 35, 's': 38, ',': 6, '5': 14, 'z': 45}\n",
      "Inverse Character Dictionary:  {0: '\\n', 1: ' ', 2: '!', 3: \"'\", 4: '(', 5: ')', 6: ',', 7: '-', 8: '.', 9: '0', 10: '1', 11: '2', 12: '3', 13: '4', 14: '5', 15: '7', 16: '8', 17: '9', 18: ':', 19: '?', 20: 'a', 21: 'b', 22: 'c', 23: 'd', 24: 'e', 25: 'f', 26: 'g', 27: 'h', 28: 'i', 29: 'j', 30: 'k', 31: 'l', 32: 'm', 33: 'n', 34: 'o', 35: 'p', 36: 'q', 37: 'r', 38: 's', 39: 't', 40: 'u', 41: 'v', 42: 'w', 43: 'x', 44: 'y', 45: 'z', 46: 'à', 47: 'é', 48: '’'}\n"
     ]
    }
   ],
   "source": [
    "## Much borrowed from https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.callbacks import LambdaCallback\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "#Helper method sampling and generating text from an RNN after training\n",
    "from SamplingAndGeneratingText import generate_text_segment\n",
    "\n",
    "text = open(\"startrekepisodes.txt\").read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocabulary_size = len(chars)\n",
    "print('total chars:', vocabulary_size)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "\n",
    "# How long is a title?\n",
    "titles = text.split('\\n')\n",
    "lengths = np.array([len(n) for n in titles])\n",
    "print(\"Max:\", np.max(lengths))\n",
    "print(\"Mean:\", np.mean(lengths))\n",
    "print(\"Median:\", np.median(lengths))\n",
    "print(\"Min:\", np.min(lengths))\n",
    "\n",
    "# hence choose 30 as seuence length to train on.\n",
    "print(\"Character Dictionary: \", char_indices)\n",
    "print(\"Inverse Character Dictionary: \", indices_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup Training Data\n",
    "\n",
    "- Cut up the corpus into semi-redundant sequences of 30 characters.\n",
    "- Change indices into \"one-hot\" vector encodings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"figures/slicing_text.png\",width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 3660\n",
      "the man trap\n",
      "charlie x\n",
      "where n\n",
      "o\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 30\n",
    "step = 3\n",
    "\n",
    "sentences = [] #The training data\n",
    "next_chars = [] #The training labels\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    \n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print(sentences[0])\n",
    "print(next_chars[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Onehot encoding:\n",
    "* a -> [1, 0, 0, ..., 0]\n",
    "* b -> [0, 1, 0, ..., 0]\n",
    "* ...\n",
    "\n",
    "Each training sample becomes 2D tensor:\n",
    "* \"This is the text\" -> X = [[0, 0, ..., 1, 0, ..., 0], ..., [0, 0, ..., 1, 0, ... 0]]\n",
    "\n",
    "Each target (next letter) becomes 1D onehot tensor:\n",
    "* a -> y = [1, 0, 0, ..., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done preparing training corpus, shapes of sets are:\n",
      "X shape: (3660, 30, 49)\n",
      "y shape: (3660, 49)\n",
      "Vocabulary of characters: 49\n"
     ]
    }
   ],
   "source": [
    "#X shape: 3D tensor. First dimension is the sentences, second is each letter in each sentence, third is the onehot\n",
    "#vector representing that letter.\n",
    "X = np.zeros((len(sentences), maxlen, vocabulary_size), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), vocabulary_size), dtype=np.bool)\n",
    "    \n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "    \n",
    "print(\"Done preparing training corpus, shapes of sets are:\")\n",
    "print(\"X shape: \" + str(X.shape))\n",
    "print(\"y shape: \" + str(y.shape))\n",
    "print(\"Vocabulary of characters:\", vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model\n",
    "\n",
    "- Model has one hidden layer of 128 LSTM cells.\n",
    "- Output layer uses the \"softmax\" activation function to output a probability distribution over next letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"figures/n-in-1-out.png\",width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#TODO: Cut out of skeleton.\n",
    "\n",
    "layer_size = 128\n",
    "# build the model: a single LSTM\n",
    "model_train = Sequential()\n",
    "\n",
    "model_train.add(LSTM(layer_size, input_shape=(maxlen, len(chars))))\n",
    "# Project back to vocabulary. One output node for each letter.\n",
    "# Dense indicates a fully connected layer.\n",
    "# Softmax activation ensures the combined values of all outputs form a probability distribution:\n",
    "# They sum to 1, with each individual value between 0 and 1.\n",
    "model_train.add(Dense(len(chars), activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               91136     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 49)                6321      \n",
      "=================================================================\n",
      "Total params: 97,457\n",
      "Trainable params: 97,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Categorical crossentropy  minimizes the distance between the probability distributions \n",
    "# output by the network and the true distribution of the targets.\n",
    "# The optimizer specifies HOW the gradient of the loss will be used to update parameters.\n",
    "# Different optimizers have different tricks to avoid local optima, etc.\n",
    "# RMSProp is adaptive, adjusting the rate of learning to how fast we're currently learning.\n",
    "# Choose one by experimenting, or selecting one documented to work well for this problem by other researchers.\n",
    "model_train.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "model_train.summary()\n",
    "\n",
    "# LSTM is more complicated than the basic RNN we introduced. It has more free parameters, therefore more parameters \n",
    "# than one might expect below. We use them since they are better at learning long-term structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training\n",
    "\n",
    "- Train on batches of 128 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Callback, which starts some text generation after each epoch.\n",
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "    diversity = 0.5 #Can be modified to change the amount of creativity in the network\n",
    "\n",
    "    generated = generate_text_segment(text, 400, diversity, model_train, maxlen, len(chars), char_indices, indices_char)\n",
    "    sys.stdout.write(generated)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- Generating with seed: \" or night\n",
      "vis à vis\n",
      "inquisitio\" or night\n",
      "vis à vis\n",
      "inquisitioenpphenpr restertwt tftrts\n",
      "omaeolt tttaoelliosdtrat r et nthosptc \n",
      "sharld\n",
      "tnlenon otftttstro\n",
      "atctrerot\n",
      "ofrectnheo\n",
      "serrtsttrserrroerottrlotlt oie e an  rolattfia rlosrrhte trn\n",
      "linro\n",
      "eiohed tot toee s\n",
      "t\n",
      "shnrt otr trat orsttstnaaroatatt\n",
      "rr\n",
      "esnrthi\n",
      "t nsernolbrte rlttniior\n",
      "tath st tsdoarlttre\n",
      "r \n",
      "rblorr\n",
      " tt trst\n",
      "otiain strts\n",
      "nas otr  pcaitrtoioret\n",
      "tttrtr\n",
      "st r ldel hlstrtowrfdtr\n",
      "t, rrthtkis oiarheft otea\n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- Generating with seed: \"ty?\n",
      "spectre of the gun\n",
      "day of \"ty?\n",
      "spectre of the gun\n",
      "day of the the the tie cie\n",
      "the the ohe theye\n",
      "the\n",
      "the the oi\n",
      "ie\n",
      "the the teectid emo oote the the there eer oy\n",
      "tamicle the dore\n",
      "the the cortee ce the the t ore e\n",
      "ore\n",
      "the the the ste ine the ior tait re thi the\n",
      "the the the eiore ce ile the the oce iie cee\n",
      "the t tent ere t e ore terenire ineeye seecer\n",
      "the iate ie te the tic de le the eare othe t eg tae the teore there the therthe the gere the the thoree se\n",
      "e\n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- Generating with seed: \"ll good things...\n",
      "tribunal\n",
      "the\"ll good things...\n",
      "tribunal\n",
      "the ias\n",
      "the \n",
      "ine \n",
      "er\n",
      "the the afiice per\n",
      "the ia t\n",
      "the e ie on\n",
      ", it in\n",
      "the care\n",
      "s af the in\n",
      "the pate\n",
      "the pare if io \n",
      "the in i\n",
      "the pan  isitr\n",
      "i\n",
      "the re the car\n",
      "t te of tie d s\n",
      "des\n",
      "the par\n",
      " oe we \n",
      "ere in  in ine s\n",
      "slin\n",
      "\n",
      "he the i\n",
      " ar\n",
      "the the on if i\n",
      "y ce s\n",
      "te ut\n",
      "e\n",
      "the tha ce pare ane in\n",
      "si\n",
      "the thi il sis if an\n",
      "s\n",
      "the tere the the ta\n",
      "cion\n",
      "\n",
      "in if in te\n",
      "ta d is\n",
      "e\n",
      "the pare if mar\n",
      " le the i\n",
      "the  one \n",
      "te ace the \n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- Generating with seed: \"d the grey\n",
      "macrocosm\n",
      "rapture\n",
      "t\"d the grey\n",
      "macrocosm\n",
      "rapture\n",
      "the heye\n",
      "the frathe she\n",
      "desthe henthe\n",
      "the hemon los of the cheic bagteis\n",
      "she part of the the patde\n",
      "the fathe\n",
      "the come, borct womave p of ce palir\n",
      "the mof part of in ane same she mache\n",
      "che seathe wod mfthe in ant in en of the comen\n",
      "the dalne\n",
      "the lomas ancen\n",
      "the the inhe he part d\n",
      "phen we palke\n",
      "cheen\n",
      "the cemen sahe  fhahe\n",
      "ine of cane\n",
      "the heathe the semance ghe cosken che the fithe moume the wemind af\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- Generating with seed: \"ked now\n",
      "code of honor 412\n",
      "the \"ked now\n",
      "code of honor 412\n",
      "the an\n",
      "the the whous of puus oute weate of the bl the shaintere io the anteromenthe the dhetretherrouse on the parthe the parthe whe the of the the the chenthe of the part irethe dhedathend\n",
      "the ghe ardesthe the the the parthe vienine barides\n",
      "the dethe the musthe unoustey\n",
      "the the deuse the merancathe mof the the dere the the deule the bhemade part in ancerthe anthe the the the murthes of the the parthe\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- Generating with seed: \"e\n",
      "shattered mirror\n",
      "the muse\n",
      "th\"e\n",
      "shattered mirror\n",
      "the muse\n",
      "the balilo\n",
      "f pars of woxt part of pars of tiviin\n",
      "the part i\n",
      " 1are of tho of tion\n",
      "iout of tion sis of the of of tion\n",
      "the wast of puster\n",
      "the mays of part r)\n",
      "the part of pars of tion\n",
      "the of time\n",
      "seack of timus of the part of mithe if til tre serace of of ey\n",
      "the parc of parkion\n",
      "\n",
      "fitige of part piia the the porr of the viss of al of partie\n",
      "the mance of or the of the rous io bait 1or part of par\n",
      "the bart \n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- Generating with seed: \"rt i\n",
      "you are cordially invited\"rt i\n",
      "you are cordially invited\n",
      "the beyare fin the balalite of the eorls\n",
      "almene deadelation\n",
      "the bsalumand of the the barion\n",
      "the wajcexind\n",
      "the mase the barate\n",
      "the enderelof the balink baldiver\n",
      "bllile workencesere\n",
      "womeghong of the al ay's and bale the barate\n",
      "beaceying\n",
      "the eniesthe seare ace in timenes\n",
      "che blathe pare the blages\n",
      "lullis and be bal's tin al eneaweralilo\n",
      "s alkes of the caige if the beadil bliles\n",
      "the blathons\n",
      "the vene\n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- Generating with seed: \"\n",
      "conundrum\n",
      "power play\n",
      "ethics\n",
      "t\"\n",
      "conundrum\n",
      "power play\n",
      "ethics\n",
      "the couns one ant woble\n",
      "bart ines of the barstere\n",
      "the eere the ance unde part ine\n",
      "the esele songe ene bente the part i\n",
      "the ciate ane deat of the the one warce cort the beyationte\n",
      "the pare ceate\n",
      "the beararce the part in of the beate\n",
      "the enge the part init te part ine\n",
      "the ine\n",
      "care evence hald the bouter\n",
      "the part on of the bart the mound\n",
      "the ceate\n",
      "the perere ane deate\n",
      "the carke wepent\n",
      "the linaene\n",
      "shea\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- Generating with seed: \"f both worlds: part two\n",
      "family\"f both worlds: part two\n",
      "family\n",
      "the hourk of fushigh\n",
      "the of ght wourn of the chart imile lof sheit the romigh on the deard of heart of the the wharg of hin say the the dehry the mpart of the fon the nemend of the deard les\n",
      "the farrtut if the way\n",
      "the the sharct of the the shart of the nof sirh stumr she deat dout sall of the mond of the of the the chars of the encarce deat of the derrd ld fat the deary of the of the doary of the\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- Generating with seed: \"shadowplay\n",
      "masks\n",
      "playing god\n",
      "e\"shadowplay\n",
      "masks\n",
      "playing god\n",
      "engo leget in the deatt\n",
      "bligitime\n",
      "the mater\n",
      "the coudd\n",
      "nichor the part i\n",
      "the the chatt 1)\n",
      "hont of and senor of tround\n",
      "seal sis and ser of the geman\n",
      "the werrt of the of the colds of the enme, part i\n",
      "\n",
      "heart fart i\n",
      "the behtt of the coung minter of the part i\n",
      "fert of the mone\n",
      "the part tion\n",
      "the the couss inte\n",
      "the scark\n",
      "the gemprotige of mattor\n",
      "sice\n",
      "spart of tho of the comte\n",
      "the wayter\n",
      "the keatt\n",
      "the wall,\n",
      "\n",
      "----- Generating text after Epoch: 10\n",
      "----- Generating with seed: \"the way to eden\n",
      "the cloud mind\"the way to eden\n",
      "the cloud mindent\n",
      "trenge impart 1)\n",
      "hart on the squrn ineart of way\n",
      "the ancerer blionte parited\n",
      "the wayil the veacksine\n",
      "the balacord\n",
      "sivingald\n",
      "squnenge deatr\n",
      "the back's and the caung in the the beaty\n",
      "the endegurater\n",
      "the warrdange part the s atiliant of ality\n",
      "and there ef the palay the logat worllime ond erre fon the deark of tine\n",
      "the anca ange warrttw\n",
      "the caarken\n",
      "the bagat the marath\n",
      "ve and cearky firiter\n",
      "the be\n",
      "\n",
      "----- Generating text after Epoch: 11\n",
      "----- Generating with seed: \"scovered country\n",
      "new ground\n",
      "he\"scovered country\n",
      "new ground\n",
      "heart of the worre workity\n",
      "inge oritht\n",
      "the cort the blore\n",
      "the encerer ent of the thel of the sagute wome\n",
      "a tiont\n",
      "the worrd the the coung wone\n",
      "the ar's and of ant wone\n",
      "the behtttion\n",
      "the part the\n",
      "these\n",
      "batite\n",
      "thes ald scapl of time\n",
      "soungite\n",
      "the one ende the cource\n",
      "come ores motht\n",
      "the work, part two\n",
      "s atication\n",
      "eretion\n",
      "the part i\n",
      "fart the esserve\n",
      "the porent of the the partity\n",
      "iever\n",
      "the enetrerd\n",
      "enderge\n",
      "\n",
      "----- Generating text after Epoch: 12\n",
      "----- Generating with seed: \"re and after\n",
      "ties of blood and\"re and after\n",
      "ties of blood and the palsion\n",
      "the wark, part two\n",
      "f init the deat of andey\n",
      "the magr, part two\n",
      "f a tathe beato\n",
      "the cara of the yamigat\n",
      "enithe parkat of andey\n",
      "the the waycoum of the the way\n",
      "qus part on\n",
      "the wayt the wemon\n",
      "the warke\n",
      "the workg fatto\n",
      "the wayt the werrs fat the weart of the part two\n",
      "f ticat of hime\n",
      "the saung math\n",
      "tre cond the wark of the wayt of ente fact on ente fattor\n",
      "the cound of hatho\n",
      "seadog mate of t\n",
      "\n",
      "----- Generating text after Epoch: 13\n",
      "----- Generating with seed: \"toys\n",
      "sarek\n",
      "ménage à troi\n",
      "trans\"toys\n",
      "sarek\n",
      "ménage à troi\n",
      "trans\n",
      "s cone sous ars of antion\n",
      "\n",
      "heat ine\n",
      "us part i\n",
      "wame, part i\n",
      "wimes\n",
      "home ard of tiok\n",
      "wime\n",
      "the porsii\n",
      "the worrt wole part i\n",
      "fars of the palt two\n",
      "f tion\n",
      "blose and loos sorkent\n",
      "hore armater\n",
      "the cont iw\n",
      "batall\n",
      "inge the beath\n",
      "workilili\n",
      "movesion\n",
      "dome ars ice\n",
      "sinition\n",
      "dove arali\n",
      "ncare of the part i\n",
      "erde beate\n",
      "woll sfare\n",
      "the ene of the parttini\n",
      "the ene\n",
      "hart ine\n",
      "the ene\n",
      "serverurs\n",
      "if are cous art of antion\n",
      "wo\n",
      "\n",
      "----- Generating text after Epoch: 14\n",
      "----- Generating with seed: \"friday's child\n",
      "the deadly year\"friday's child\n",
      "the deadly yeart of t29o2\n",
      "the parstignt\n",
      "furemate\n",
      "deat of the pa4tling 94 part two\n",
      "f ttrends adser\n",
      "th9 coudligat of on anpi9n9r matel4\n",
      "’quge and lead\n",
      "the9 zarnd\n",
      "the pazter\n",
      "the enemun4 of the parthence fart i\n",
      "9a4t war\n",
      "deyond ard 2\n",
      "the sarr4a bofle ald star\n",
      "the em9e4re part i\n",
      "fars o4 the car4s(9ark squdly ard7ig\n",
      "the9 4am44d2\n",
      "the?e9 fright2\n",
      "the 0rattre of th99cordand\n",
      "cald sind\n",
      "s tile the499s and t9er\n",
      "t9manc9ar\n",
      "the a\n",
      "\n",
      "----- Generating text after Epoch: 15\n",
      "----- Generating with seed: \"haotica!\n",
      "gravity\n",
      "the emperor's\"haotica!\n",
      "gravity\n",
      "the emperor's art 1)\n",
      "herrt wam\n",
      "ferre, part one\n",
      "the searce fatte\n",
      "fartion mas\n",
      "searkes ante\n",
      "the watct he comening\n",
      "the adger mathe\n",
      "darkitrix (and\n",
      "the warrs of the deat\n",
      "the expagment\n",
      "the palsting\n",
      "the ene wime\n",
      "the partity on the parthin\n",
      "the walll watto\n",
      "stattion\n",
      "armective ad\n",
      "hondrestren of wime\n",
      "the magalin\n",
      "the magl chound\n",
      "the warrn homestor\n",
      "the saldgond\n",
      "shatcoss part 1)\n",
      "hamongh of and seators\n",
      "imugatco\n",
      "the adargignt\n",
      "f\n",
      "\n",
      "----- Generating text after Epoch: 16\n",
      "----- Generating with seed: \"mesters of triskelion\n",
      "a piece \"mesters of triskelion\n",
      "a piece for parter\n",
      "the magdoint\n",
      "the bey's collden\n",
      "the counte frollo\n",
      "works ald\n",
      "sarper's art i)\n",
      "artece ses coustitime\n",
      "devild lithe\n",
      "the behald\n",
      "the coundicat onconga coull y\n",
      "the thelt watho\n",
      "y\n",
      "the beatt\n",
      "the xpart 1)\n",
      "homossare home ormey\n",
      "the childisnd\n",
      "the wallsing tring\n",
      "the parckitine\n",
      "seadigatcen of the mond shay\n",
      "the plichive\n",
      "scabligat\n",
      "fus part one\n",
      "scace\n",
      "the palsion mance\n",
      "parision\n",
      "choisinn watto\n",
      "the peat the be\n",
      "\n",
      "----- Generating text after Epoch: 17\n",
      "----- Generating with seed: \"de of honor 412\n",
      "the last outpo\"de of honor 412\n",
      "the last outposs\n",
      "armegs\n",
      "the mund\n",
      "the the shayes\n",
      "warkitw\n",
      "veril of the magsiinted\n",
      "the bauthine\n",
      "home ourn countion\n",
      "armang\n",
      "the magad\n",
      "squngatro\n",
      "mageord\n",
      "siad\n",
      "sapagion\n",
      "mace\n",
      "erfon the ene fattlo\n",
      "somuladss\n",
      "shine\n",
      "the angect\n",
      "mage of the anterce sond of bay\n",
      "albenge houl the coudiny impart 1)\n",
      "homeou maghe\n",
      "the of thing\n",
      "blige of the magstin\n",
      "the adgime\n",
      "the emeng artion\n",
      "almigntince beate\n",
      "felice\n",
      "sevenis ard in\n",
      "a beathis\n",
      "sheace\n",
      "m\n",
      "\n",
      "----- Generating text after Epoch: 18\n",
      "----- Generating with seed: \"stant voices\n",
      "through the looki\"stant voices\n",
      "through the lookight\n",
      "falice, part i\n",
      "fars part iis\n",
      "armagion\n",
      "countine seate\n",
      "farices of wiliti\n",
      "the cound swace\n",
      "the coungigatco\n",
      "spart ine\n",
      "the peattine\n",
      "the dead shatcous part one\n",
      "icaacdivios\n",
      "ineered gine\n",
      "shedos darkes part i\n",
      "fhoss ard one\n",
      "the mausentine\n",
      "the behatter\n",
      "the ceastence sond sary\n",
      "the searck mither\n",
      "deates part on ence urition\n",
      "vision and in ente\n",
      "the leat of the mend\n",
      "the walckinmtruns\n",
      "the way\n",
      "the beathen of the \n",
      "\n",
      "----- Generating text after Epoch: 19\n",
      "----- Generating with seed: \"is\n",
      "a time to stand\n",
      "revulsion\n",
      "r\"is\n",
      "a time to stand\n",
      "revulsion\n",
      "rovesion\n",
      "chilbinntrevess\n",
      "wrec\n",
      "the mard, part i\n",
      "e\n",
      "the part the\n",
      "shode adond\n",
      "hirion\n",
      "armeg\n",
      "the warrt fle the bartury\n",
      "the wordssy\n",
      "dearl of the plice\n",
      "thes ard one\n",
      "the warttore\n",
      "the wild\n",
      "erokion\n",
      "countine\n",
      "the count of the gapoth\n",
      "dretorsssard\n",
      "seare, part i\n",
      "farer, descrithin\n",
      "the behild\n",
      "inge miretin\n",
      "the searc, part i\n",
      "unem walt\n",
      "the arting\n",
      "barite\n",
      "the warrt fart ofe\n",
      "the mpart geof shortor of antenc\n",
      "vercore of the\n",
      "Training done\n"
     ]
    }
   ],
   "source": [
    "# Training the Model. history captures data for plotting (e.g loss)\n",
    "print(\"training start\")\n",
    "#Setting up a callback, which will generate example text from the network during training.\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "history = model_train.fit(X, y, batch_size=128, epochs=20, verbose=0, callbacks=[print_callback])\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save model if necessary\n",
    "model_train.save(\"keras-startrek-LSTM-model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Plotting training and validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWRYnBjMzy+LEYGZmWf4/nhfLA7IN5SgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f608c4f5fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
