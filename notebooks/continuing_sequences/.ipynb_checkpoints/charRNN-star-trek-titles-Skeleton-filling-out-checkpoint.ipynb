{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Character Level RNN using LSTM cells.\n",
    "\n",
    "- Trains on Star Trek episode titles\n",
    "- Outputs \"fake\" titles.\n",
    "\n",
    "Much comes from a [Keras example](https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py).\n",
    "\n",
    "## Setup Environment\n",
    "\n",
    "- Import Keras\n",
    "- Open up the Star Trek corpus\n",
    "- We need to translate the textual data into a format that the RNN can accept as input.\n",
    "- Give each letter an index and create dictionaries to translate from index to character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 11010\n",
      "total chars: 49\n",
      "Max: 50\n",
      "Mean: 14.001362397820163\n",
      "Median: 13.0\n",
      "Min: 2\n",
      "Character Dictionary:  {'t': 39, '(': 4, 'e': 24, 'h': 27, '3': 12, '5': 14, '-': 7, '8': 16, 'q': 36, '2': 11, ')': 5, '1': 10, 'b': 21, '9': 17, '.': 8, 'u': 40, 'd': 23, 'm': 32, 'l': 31, 'g': 26, ',': 6, 'n': 33, '0': 9, '4': 13, ' ': 1, 'à': 46, 'y': 44, 'f': 25, 'é': 47, '7': 15, 'v': 41, 'c': 22, '?': 19, 'i': 28, 'x': 43, 'r': 37, 'a': 20, '!': 2, ':': 18, 'p': 35, 'w': 42, 'j': 29, 'o': 34, 'k': 30, \"'\": 3, '’': 48, 'z': 45, '\\n': 0, 's': 38}\n",
      "Inverse Character Dictionary:  {0: '\\n', 1: ' ', 2: '!', 3: \"'\", 4: '(', 5: ')', 6: ',', 7: '-', 8: '.', 9: '0', 10: '1', 11: '2', 12: '3', 13: '4', 14: '5', 15: '7', 16: '8', 17: '9', 18: ':', 19: '?', 20: 'a', 21: 'b', 22: 'c', 23: 'd', 24: 'e', 25: 'f', 26: 'g', 27: 'h', 28: 'i', 29: 'j', 30: 'k', 31: 'l', 32: 'm', 33: 'n', 34: 'o', 35: 'p', 36: 'q', 37: 'r', 38: 's', 39: 't', 40: 'u', 41: 'v', 42: 'w', 43: 'x', 44: 'y', 45: 'z', 46: 'à', 47: 'é', 48: '’'}\n"
     ]
    }
   ],
   "source": [
    "## Much borrowed from https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
    "\n",
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import LambdaCallback\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "\n",
    "text = open(\"startrekepisodes.txt\").read().lower()\n",
    "print('corpus length:', len(text))\n",
    "\n",
    "chars = sorted(list(set(text)))\n",
    "vocabulary_size = len(chars)\n",
    "print('total chars:', vocabulary_size)\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "\n",
    "# How long is a title?\n",
    "titles = text.split('\\n')\n",
    "lengths = np.array([len(n) for n in titles])\n",
    "print(\"Max:\", np.max(lengths))\n",
    "print(\"Mean:\", np.mean(lengths))\n",
    "print(\"Median:\", np.median(lengths))\n",
    "print(\"Min:\", np.min(lengths))\n",
    "\n",
    "# hence choose 30 as seuence length to train on.\n",
    "print(\"Character Dictionary: \", char_indices)\n",
    "print(\"Inverse Character Dictionary: \", indices_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Setup Training Data\n",
    "\n",
    "- Cut up the corpus into semi-redundant sequences of 30 characters.\n",
    "- Change indices into \"one-hot\" vector encodings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"figures/slicing_text.png\",width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 3660\n",
      "the man trap\n",
      "charlie x\n",
      "where n\n",
      "o\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 30\n",
    "step = 3\n",
    "\n",
    "sentences = [] #The training data\n",
    "next_chars = [] #The training labels\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i+maxlen])\n",
    "    next_chars.append(text[i+maxlen])\n",
    "    \n",
    "print('nb sequences:', len(sentences))\n",
    "\n",
    "print(sentences[0])\n",
    "print(next_chars[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Onehot encoding:\n",
    "* a -> [1, 0, 0, ..., 0]\n",
    "* b -> [0, 1, 0, ..., 0]\n",
    "* ...\n",
    "\n",
    "Each training sample becomes 2D tensor:\n",
    "* \"This is the text\" -> X = [[0, 0, ..., 1, 0, ..., 0], ..., [0, 0, ..., 1, 0, ... 0]]\n",
    "\n",
    "Each target (next letter) becomes 1D onehot tensor:\n",
    "* a -> y = [1, 0, 0, ..., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done preparing training corpus, shapes of sets are:\n",
      "X shape: (3660, 30, 49)\n",
      "y shape: (3660, 49)\n",
      "Vocabulary of characters: 49\n"
     ]
    }
   ],
   "source": [
    "#X shape: 3D tensor. First dimension is the sentences, second is each letter in each sentence, third is the onehot\n",
    "#vector representing that letter.\n",
    "X = np.zeros((len(sentences), maxlen, vocabulary_size), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), vocabulary_size), dtype=np.bool)\n",
    "    \n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1\n",
    "    \n",
    "print(\"Done preparing training corpus, shapes of sets are:\")\n",
    "print(\"X shape: \" + str(X.shape))\n",
    "print(\"y shape: \" + str(y.shape))\n",
    "print(\"Vocabulary of characters:\", vocabulary_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model\n",
    "\n",
    "- Model has one hidden layer of 128 LSTM cells.\n",
    "- Output layer uses the \"softmax\" activation function to output a probability distribution over next letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"figures/n-in-1-out.png\",width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Build model\n",
    "\n",
    "layer_size = 128\n",
    "model_train = Sequential()\n",
    "\n",
    "model_train.add(LSTM(layer_size, input_shape=(maxlen, len(chars))))\n",
    "model_train.add(Dense(len(chars), activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               91136     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 49)                6321      \n",
      "=================================================================\n",
      "Total params: 97,457\n",
      "Trainable params: 97,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Compile and summarize model\n",
    "model_train.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "model_train.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"figures/reweighting.png\",width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Higher diversity -> more randomness in the generation.\n",
    "def sample(probability_distribution, diversity=1.0):\n",
    "    # helper function to sample an index from a probability distribution\n",
    "    probability_distribution = np.asarray(probability_distribution).astype('float64')\n",
    "    probability_distribution = np.log(probability_distribution) / diversity\n",
    "    exp_preds = np.exp(probability_distribution)\n",
    "    probability_distribution = exp_preds / np.sum(exp_preds)\n",
    "    #Draws 1 element at random according to the new scaled probability-distribution.\n",
    "    probabilities = np.random.multinomial(n=1, pvals = probability_distribution) \n",
    "    return np.argmax(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Method for printing some example text after every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_text_segment(length, diversity, generating_model = model_train, input_sequence_length = maxlen):\n",
    "    start_index = random.randint(0, len(text) - input_sequence_length - 1)\n",
    "\n",
    "    # We need a seed to start the text generation. Since during training the ANN always experiences\n",
    "    # sentences of size 30, we seed it with a sentence of length 30 to get it into a sensible state.\n",
    "    generated = ''\n",
    "    sentence = text[start_index: start_index + input_sequence_length]\n",
    "    generated += sentence\n",
    "    \n",
    "    sys.stdout.write('----- Generating with seed: \"' + sentence + '\"')\n",
    "\n",
    "    for i in range(length):\n",
    "        x_pred = np.zeros((1, input_sequence_length, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        predictions_distribution = generating_model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(predictions_distribution, diversity)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        #Stepping one symbol forward in the sentence\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    # Function invoked at end of each epoch. Prints generated text.\n",
    "    print()\n",
    "    print('----- Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    for diversity in [0.5]:#[0.2, 0.5, 1.0, 1.2]:\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = generate_text_segment(400, diversity, model_train, input_sequence_length = maxlen)\n",
    "        sys.stdout.write(generated)\n",
    "        print()\n",
    "        \n",
    "\n",
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training\n",
    "\n",
    "- Train on batches of 128 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training start\n",
      "\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"captive pursuit\n",
      "aquiel\n",
      "q-less\n",
      "\"captive pursuit\n",
      "aquiel\n",
      "q-less\n",
      "tnmor ooo ,oat orlootognanoc\n",
      "oe ienondwoooolo\n",
      "teo aipioi\n",
      "gomeooanioeon\n",
      "ol \n",
      "id  soeooioonoeenogoapioo\n",
      "voe\n",
      "t o\n",
      "ilditgro\n",
      "no geotoin ioo soa ooleagonneoomnathtooi\n",
      "diceoiaioeo eiinooh apoo\n",
      "gdonooooiopuoaeono ior pinoroo\n",
      "n\n",
      "ngs\n",
      "eoelo beanonsorovnldeeeo\n",
      "nlod isii ovaososoo oilo\n",
      "o ne onoenonoais onmenos o ro\n",
      "onneveoesooaos oedneopi danisegl thp\n",
      "oerii \n",
      " otosooc  n eeoonnaroo\n",
      " nd caree\n",
      "olns mlioogrhnoonelog \n",
      "\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"re tribbles, more troubles\n",
      "the\"re tribbles, more troubles\n",
      "the thergathe orhepteotheothe pare ope\n",
      "the the oeororusintha eribtiomeethe ouurtheathe therthe\n",
      "themormacesethe liiothe othcd\n",
      "a the the oeo the ooreotheythdethe thu hirthentheopenathe porathe the oueophi\n",
      "thenthe the the thhathe the erthe\n",
      "eo oamtepoylthe oothevtteorio\n",
      "the the che pa ponthe he thorthes\n",
      "hoop oatomathemt patedese ohhe ehhe oalsocabathe aothe paspthe the dethe coohpacooa onthe pa\n",
      "the mame \n",
      "\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"orrow\n",
      "patterns of force\n",
      "by any\"orrow\n",
      "patterns of force\n",
      "by any pare the fagt one ofrt ont the paro ce deon\n",
      "iferan\n",
      "the pant sing par\n",
      "imees\n",
      "the \n",
      "or the pont oreg\n",
      "s ona int er\n",
      "ale\n",
      "the pare ofate jay\n",
      "the s\n",
      "thecesthe cerd\n",
      "the se\n",
      "thedd\n",
      "gedescede\n",
      "the parte\n",
      "the parc or\n",
      "the pant thes\n",
      "the the onctar\n",
      "the tout par\n",
      "the de\n",
      "the cant bagt bame part ari\n",
      "the part on\n",
      "the thead ont e\n",
      "the of sela pant orn pare sf pad the the par oreorertil the thengimealige the the the the caric\n",
      "\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"sion\n",
      "critical care\n",
      "inside man\n",
      "\"sion\n",
      "critical care\n",
      "inside man\n",
      "the s\n",
      "are corast un caress\n",
      "ay the ssarks\n",
      "se soss\n",
      "fare\n",
      "the sast an\n",
      "somis\n",
      "sert als\n",
      "sredss sarigs sas\n",
      "the saror\n",
      "the sesthe the the paiessas\n",
      "the vedis\n",
      "the sacess\n",
      "saresssaris sormlod\n",
      "sous\n",
      "sarcsss\n",
      "are sonears\n",
      "the bard sard\n",
      "sare sond sydpakt of aresstasstilesthe the sars\n",
      "sides\n",
      "souss\n",
      "sart of of the the sgarssparts paros, artabllssof the searss\n",
      "slagrescofs\n",
      "of s\n",
      "foast suar bart ersssond jayasis faras\n",
      "same s\n",
      "\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" end\n",
      "the maquis, part i\n",
      "firstb\" end\n",
      "the maquis, part i\n",
      "firstbin\n",
      "the want the bation\n",
      "the parte\n",
      "the the gemante\n",
      "the parin\n",
      "the part in\n",
      "the santate\n",
      "hemar\n",
      "the the the shathe the fontere\n",
      "the arinntircent ondonbenten\n",
      "the doesenir\n",
      "the londise partor\n",
      "the the wethe wone\n",
      "the the satertinn\n",
      "the partin\n",
      "the secinn\n",
      "thee of indes\n",
      "the part on\n",
      "the partirk\n",
      "the the wanter\n",
      "the funster\n",
      "banken\n",
      "sind sunt the venor\n",
      "the parti1s\n",
      "the the the hemten\n",
      "the part on\n",
      "the partren\n",
      "the the go th\n",
      "\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" communicator\n",
      "singularity\n",
      "vani\" communicator\n",
      "singularity\n",
      "vanione ifirerithe part or\n",
      "sarteror\n",
      "the ard urter\n",
      "the herre of the soressice part i\n",
      "the the comone the acerathir the part r\n",
      "the coutaline\n",
      "the comelirise aresis icsisser\n",
      "the hoarmof bas of the of inerpor\n",
      "the pars of the coumone nithe part of ares\n",
      "the cage sareros\n",
      "are uale wory the part of ard part par\n",
      "of arter\n",
      "the couthe of onter\n",
      "the part i\n",
      "the homenrer\n",
      "the searare\n",
      "the doethore\n",
      "homedidathesror\n",
      "the daru\n",
      "\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"armok\n",
      "ensign ro\n",
      "silicon avatar\"armok\n",
      "ensign ro\n",
      "silicon avatar\n",
      "the marte\n",
      "won the of the of the bart twe\n",
      "sorder\n",
      "the the birt 1111111111111111111111111111113à’ààààà0àà7àà!’àà!à0!àààà\n",
      "the meront mon the mering of the litard floraine in the diand of fathie\n",
      "the mort 1yien of the part the\n",
      "the part i)\n",
      "tre of the the the deace un sare of herre ferter\n",
      "the re the wcare\n",
      "the the uust of ont fart 11oi)\n",
      "the ne on eune\n",
      "the wart ine\n",
      "the re shis are part te\n",
      "sorse af the the \n",
      "\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" moon\n",
      "prodigal daughter\n",
      "latent\" moon\n",
      "prodigal daughter\n",
      "latente\n",
      "sordes\n",
      "aices\n",
      "of erte\n",
      "couctor\n",
      "sor\n",
      "the wejt of lens\n",
      "the urtir\n",
      "the memord\n",
      "the part ofe\n",
      "the peation\n",
      "the are se\n",
      "the part of\n",
      "the of lithis ance of the lon the erion\n",
      "serusal me\n",
      "partere\n",
      "the uent ine part o\n",
      "te\n",
      "the port of le\n",
      "the part or\n",
      "the ceart ofe\n",
      "doone\n",
      "soun parter\n",
      "the wopor\n",
      "the imence\n",
      "cimpoote\n",
      "the bortion\n",
      "of the beate\n",
      "the uetor\n",
      "the porter\n",
      "the unt inition\n",
      "cove\n",
      "borature\n",
      "the enel mond\n",
      "shere of bis\n",
      "are d\n",
      "\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ge of heart\n",
      "wrongs darker than\"ge of heart\n",
      "wrongs darker than the cofmigh wiry pard stho phork phorrt en mance and serr sthe meard of barc fur the cound\n",
      "the spark shome the dearc for chance word shors rnar dof wang the ond prace\n",
      "the ersinn\n",
      "wart of herome, part i\n",
      "pletro dor dur link\n",
      "the anter monkes\n",
      "shight in the nemend if the spart wof deac\n",
      "dof blord the bact of mind deart of the prattro te an the parat of hime\n",
      "the veerd\n",
      "the umeng\n",
      "the and ghe comance frithi\n",
      "\n",
      "----- Generating text after Epoch: 9\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"omestead\n",
      "renaissance man\n",
      "endga\"omestead\n",
      "renaissance man\n",
      "endgase\n",
      "a fait ofe\n",
      "the paot tio\n",
      "mart of her of tine\n",
      "the ender of the sear\n",
      "the couss\n",
      "the wion of anter\n",
      "the lemen\n",
      "the searc feer of wate\n",
      "the saring of one of witer\n",
      "comel of the parcition\n",
      "daact ofe coot of inter of the boostion\n",
      "firat of sighe\n",
      "spart i\n",
      "ere searc of wini\n",
      "stave ssarr ofes arter of hine\n",
      "the fatco\n",
      "wous of lige\n",
      "the warkt of ar\n",
      "the coumpait of ent lel of the coad of wite\n",
      "the coust of firi\n",
      "the par\n",
      "\n",
      "----- Generating text after Epoch: 10\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ter-clock incident\n",
      "the motion \"ter-clock incident\n",
      "the motion inn\n",
      "dive the chad ance\n",
      "the bethe mogh erity\n",
      "\n",
      "hade hort of the the lige the the vincance cadbey\n",
      "arl fachile\n",
      "the paination\n",
      "\n",
      "the monget of highin\n",
      "the weand anc endester\n",
      "the coghe the woushin\n",
      "the waturer\n",
      "the heart of hichance heal ferester\n",
      "the enagher\n",
      "the deark\n",
      "woocouss\n",
      "the brathinn\n",
      "the cousticion\n",
      "chechild and shideat one anc ine ance the mighin\n",
      "the the ant the chighe wois\n",
      "the cougnt repar in\n",
      "the vewi\n",
      "\n",
      "----- Generating text after Epoch: 11\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"e expanse\n",
      "the xindi\n",
      "anomaly\n",
      "ex\"e expanse\n",
      "the xindi\n",
      "anomaly\n",
      "exige\n",
      "scathor dof firrt of wathin dof hor lof in the shard\n",
      "fur the shar\n",
      "the swar\n",
      "the seark\n",
      "the wark wo al fer of the phopor\n",
      "the doudlin the mag al of enke\n",
      "sulime\n",
      "ury ar part of hime\n",
      "the dearn ffin the maturr\n",
      "the dear\n",
      "the warri\n",
      "fesing\n",
      "dear\n",
      "the deade\n",
      "the mork farcis of the warr\n",
      "the deackatre of high\n",
      "the sariint\n",
      "far the dead\n",
      "the the chos at wink\n",
      "the mand umen\n",
      "the dearn\n",
      "forkss sid ar of intey far\n",
      "the do\n",
      "\n",
      "----- Generating text after Epoch: 12\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"re\n",
      "second sight\n",
      "inheritance\n",
      "sa\"re\n",
      "second sight\n",
      "inheritance\n",
      "savena comenter\n",
      "the ant the ninter of highin the deame\n",
      "the behe duall fettrestors of kent\n",
      "the deatrors of the mather of hemor\n",
      "dof the part in\n",
      "the meime part i\n",
      "fert of fethion\n",
      "mof wive\n",
      "the part iplon\n",
      "the and of the moth rime\n",
      "the most on the mond day\n",
      "partes\n",
      "andence bust part ofe mithe battlles cove\n",
      "focthond\n",
      "shenterror\n",
      "comewar\n",
      "dofatime\n",
      "scacentrer of the the woussion\n",
      "code the ligh ntter of the wint of t\n",
      "\n",
      "----- Generating text after Epoch: 13\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"zoid man\n",
      "unnatural selection\n",
      "a\"zoid man\n",
      "unnatural selection\n",
      "artences\n",
      "arterce\n",
      "covalige\n",
      "the deack\n",
      "arce werder\n",
      "rone of wige\n",
      "the bogs of hel of the poretion\n",
      "ermence beyion\n",
      "care of mathe battlo\n",
      "line\n",
      "countor\n",
      "the one us on\n",
      "ald ond caratio\n",
      "\n",
      "hese of the bight\n",
      "bay's dear\n",
      "the onge ont pact on\n",
      "unterte conge\n",
      "countion\n",
      "\n",
      "he one vight on\n",
      "arce of hetror\n",
      "sordon\n",
      "ar of home\n",
      "the bost one\n",
      "acenge\n",
      "couve\n",
      "the couge of the parcorte\n",
      "covalicald\n",
      "the coustion\n",
      "\n",
      "hewoonh\n",
      "shich de rither of t\n",
      "\n",
      "----- Generating text after Epoch: 14\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"d\n",
      "the drumhead\n",
      "half a life\n",
      "the\"d\n",
      "the drumhead\n",
      "half a life\n",
      "the erengericor\n",
      "the empene home of the palge homens\n",
      "ald selien cont the ligh warr\n",
      "s of al ey ere sher of the piospoime\n",
      "sorne of the phish\n",
      "treye ald swach\n",
      "s ant the veade\n",
      "the alenge home ald shine\n",
      "the peach codl fect fall, part twe\n",
      "the douglor deescond\n",
      "the mountur de anmespe\n",
      "the bectull's ar\n",
      "the eregh er ount\n",
      "the emenge rome (part 1)\n",
      "demerder\n",
      "the searc of the phish word le and of hime\n",
      "the moss und the\n",
      "\n",
      "----- Generating text after Epoch: 15\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"lepod one\n",
      "fusion\n",
      "rogue planet\n",
      "\"lepod one\n",
      "fusion\n",
      "rogue planet\n",
      "fullll ferrt fil the chaturel of the plishios of the part on\n",
      "the dear\n",
      "the battllow\n",
      "the veascigh restre of the wiry\n",
      "the assinn\n",
      "foretion\n",
      "farssion\n",
      "caretu\n",
      "l fear\n",
      "the of the day\n",
      "sigh rossin\n",
      "the ar touss\n",
      "s arkis: part oni\n",
      "actorms\n",
      "sherrouds\n",
      "mond\n",
      "umer\n",
      "croumen\n",
      "the wayt of fathio\n",
      "the waytrresion\n",
      "fart ofight\n",
      "bastly\n",
      "squyurator\n",
      "shencorrr\n",
      "the cougrorithe of the wiom\n",
      "the waycor\n",
      "the waycorm\n",
      "the empentrry of the s\n",
      "\n",
      "----- Generating text after Epoch: 16\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"sistence of vision\n",
      "rejoined\n",
      "st\"sistence of vision\n",
      "rejoined\n",
      "stare, part ii\n",
      "time ard sinte part in\n",
      "the searssin\n",
      "covelse riskical wofse\n",
      "baldls, part ii\n",
      "time af tive\n",
      "scarest, part ii\n",
      "inden plife\n",
      "mane and silicancene\n",
      "the coustivion\n",
      "invedencm\n",
      "simprome\n",
      "sordgerr\n",
      "remen\n",
      "gemen\n",
      "trming first fler\n",
      "mof an ingerper\n",
      "tre apenter\n",
      "the wovelor\n",
      "mond ard parfe\n",
      "the wousd of the peappoctic, part ii\n",
      "erdendar\n",
      "dovalan perpar\n",
      "the peathis\n",
      "dorestovion aumay\n",
      "dondos and sirca\n",
      "omenal dof si\n",
      "\n",
      "----- Generating text after Epoch: 17\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"altz\n",
      "waking moments\n",
      "message in\"altz\n",
      "waking moments\n",
      "message in the mand sint feimpil\n",
      "the deamorif the ligh the plochituescove\n",
      "silithe\n",
      "repliom\n",
      "coveldes\n",
      "armels\n",
      "the coutle of lithe coutllove\n",
      "poratyiss ivile\n",
      "the nearctive\n",
      "siint\n",
      "the omigrorss lear\n",
      "the logs of ligh rither\n",
      "the veaco\n",
      "breal firnty an the phime\n",
      "tiemden\n",
      "rome (part i)\n",
      "fricong metriviom\n",
      "the coumulile\n",
      "the coumniin\n",
      "the hiud lintey of the wionmience\n",
      "the coudd stimater of fithor\n",
      "dome and sing umath\n",
      "wlond\n",
      "she\n",
      "\n",
      "----- Generating text after Epoch: 18\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"rspective\n",
      "yesterday's enterpri\"rspective\n",
      "yesterday's enterprite\n",
      "corture\n",
      "the womende mind\n",
      "dayist balis the dound\n",
      "sind ald sincerer\n",
      "the dead\n",
      "the mond unniod\n",
      "erter\n",
      "firstivalacomends and silion\n",
      "iveedcere\n",
      "the dousn the plithis dead\n",
      "the mogh us in tulls dead\n",
      "the dayals frent\n",
      "the countivion\n",
      "encenderiom\n",
      "the the kigina\n",
      "first and the plishes lomendss rryalicove\n",
      "worsplade\n",
      "brose blond\n",
      "shadors of migh rrmen\n",
      "the squyures of wime\n",
      "the deadn of the domenus dark ferithe sond\n",
      "\n",
      "----- Generating text after Epoch: 19\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"hreshold\n",
      "meld\n",
      "return to grace\n",
      "\"hreshold\n",
      "meld\n",
      "return to grace\n",
      "the of the dayise\n",
      "scarct on\n",
      "for the\n",
      "umenerive part in\n",
      "the waycord lestive\n",
      "scart on\n",
      "laress\n",
      "matarct, part i\n",
      "plran of the gion\n",
      "ond ligh rame\n",
      "the worse of the dounlis\n",
      "coven\n",
      "teming of the ghe hourl the worspicadocs\n",
      "are theer\n",
      "the cousurero\n",
      "shit of forithe\n",
      "sorcalce, part ii\n",
      "tame an an cous of the porgety\n",
      "soremone\n",
      "actenter\n",
      "the couencion\n",
      "dokess...n\n",
      "dle of the daturr\n",
      "the countion\n",
      "\n",
      "the countion\n",
      "remon\n",
      "shoreve\n",
      "\n",
      "Training done\n"
     ]
    }
   ],
   "source": [
    "# Training the Model. Capture history for some plotting\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "print(\"training start\")\n",
    "history = model_train.fit(X, y, batch_size=128, epochs=20, verbose=0, callbacks=[print_callback, TQDMNotebookCallback()])\n",
    "print(\"Training done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Plotting training and validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEZCAYAAACTsIJzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbpgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2f256e8400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Make a Decoder model\n",
    "\n",
    "During training, we presented sequences of 30 characters, along with the correct next character.\n",
    "When_using the trained model, it may be more useful to feed in 1 character at a time, and seeing the next\n",
    "predicted one. That will also convince us that the network is actually _using_ its internal state.\n",
    "\n",
    "- Needs input length of 1.\n",
    "- Needs batch size of 1\n",
    "- Needs LSTM to be stateful\n",
    "- check that params is the same as model_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<img src=\"figures/1-in-1-out.png\",width=800>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build a decoding model (input length 1, batch size 1, stateful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Test the Model\n",
    "\n",
    "- Take a quote then add 400 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Sample 1000 characters from the decoding model using a random seed from the vocabulary.\n",
    "generated = generate_text_segment(1000, diversity=0.5, generating_model = model_dec, input_sequence_length = 1)\n",
    "sys.stdout.write(generated)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
